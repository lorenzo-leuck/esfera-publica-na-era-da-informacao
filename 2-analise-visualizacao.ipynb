{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17196f40-7d06-4209-97c8-74aae6cfd330",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0 - Setup do Sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d005855-86c2-4ce4-8be3-920f1cb237f0",
   "metadata": {},
   "source": [
    "## 0.1 - Importa os módulos utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7a8ee-1b1f-4567-9e2a-ceca803a7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import kaleido\n",
    "import matplotlib\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "import string\n",
    "import decimal\n",
    "import requests\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from fuzzywuzzy import process\n",
    "import gspread\n",
    "import tweepy \n",
    "from tweepy import OAuthHandler\n",
    "import time\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import codecs\n",
    "import os.path\n",
    "from os.path import join as pjoin\n",
    "import glob\n",
    "import json\n",
    "from io import StringIO\n",
    "from io import open\n",
    "from urllib.request import urlopen\n",
    "from itertools import chain\n",
    "import os\n",
    "import csv\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "# import re as regex\n",
    "# import regex as re\n",
    "# import re\n",
    "from tabulate import tabulate\n",
    "from csv import DictReader\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.readwrite import json_graph\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import chart_studio.plotly as chs\n",
    "import cufflinks as cf\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "import time\n",
    "from requests.exceptions import HTTPError\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "import json\n",
    "\n",
    "import ijson\n",
    "from datetime import datetime\n",
    "import glob\n",
    "# import matplotlib.pyplot as plt, mpld3\n",
    "from dateutil.parser import parse\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Make Plotly work in your Jupyter Notebook\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# Use Plotly locally\n",
    "cf.go_offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a82a5-dee1-432f-af1d-529f886622c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0.2 - Carrega a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414b70d-755d-4f82-a3d2-ccb6c451b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDeputados = pd.read_csv(\"db-listaDeputados.csv\")\n",
    "print(listaDeputados.columns)\n",
    "# pd.set_option('max_columns', None)\n",
    "# listaDeputados.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ff41a-be6b-4cb7-918b-2b22529391ca",
   "metadata": {},
   "source": [
    "## 0.3 - Formata rótulos das base de dados para as tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6b2c5-7597-4384-976e-bb0f4d6ada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepCol = ['GENERO', 'COR_RACA', 'ESTADO_CIVIL','ESCOLARIDADE', 'OCUPACAO_ANTERIOR','FAIXA_ETARIA','PARTIDO_ATUAL', 'IDEOLOGIA_PARTIDO_ATUAL','MILIONARIO','TEM_TWITTER','ESTADO_ELEICAO','REGIAO_ELEICAO','ST_REELEICAO', 'AGRUPAMENTO_IDADE','AGRUPAMENTO_BENS','AGRUPAMENTO_VOTOS','AGRUPAMENTO_SEGUIDORES', 'AGRUPAMENTO_BALANCO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS', 'AGRUPAMENTO_BALANCO_TWEETS']\n",
    "\n",
    "listaDeputados_F = listaDeputados[keepCol]\n",
    "\n",
    "listaDeputados_F = listaDeputados_F.rename(columns={'GENERO':'Gênero','COR_RACA':'Cor/Raça','ESTADO_CIVIL':'Estado Civil','ESCOLARIDADE':'Escolaridade','OCUPACAO_ANTERIOR':'Ocupação anterior','FAIXA_ETARIA':'Faixa etária','PARTIDO_ATUAL':'Partido','IDEOLOGIA_PARTIDO_ATUAL':'Ideologia','MILIONARIO':'Maioria milionária','TEM_TWITTER':'Tem twitter','ESTADO_ELEICAO':'Estado','REGIAO_ELEICAO':'Região','ST_REELEICAO':'Reeleito','AGRUPAMENTO_IDADE':'AG Idade', 'AGRUPAMENTO_VOTOS':'AG Votos','AGRUPAMENTO_SEGUIDORES': 'AG Seguidores', 'AGRUPAMENTO_BALANCO_SEGUIDORES':'AG Balanço de Seguidores','AGRUPAMENTO_NUMERO_TWEETS':'AG Número de Tweets','AGRUPAMENTO_BALANCO_TWEETS':'AG Balanço de Tweets','AGRUPAMENTO_BENS':'AG Bens'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86f587-d468-4346-99ad-13de635ebcd5",
   "metadata": {},
   "source": [
    "# 1 - Análise exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52106b4-65bf-47b2-8c90-4d1a1d6f7f29",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 - Levanta coluna generica para as funções de agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd7cfc-b1e3-470c-b0ca-ebd72062eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDeputados_F['new'] = 'a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f031d-f97f-4e31-8402-cc8b11d4c9aa",
   "metadata": {},
   "source": [
    "## 1.2 - Filtra a base de dados por deputados gaúchos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e11e1-30b6-4597-ae7e-7bb98f55a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDeputados_rs = listaDeputados_F[(listaDeputados_F['Estado']=='RS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da18447-342c-4ca1-ae33-17cdb915cfd2",
   "metadata": {},
   "source": [
    "## 1.3 - Cria tabela de características gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29edea-61dd-4ac2-8419-83355163c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero = listaDeputados.value_counts()\n",
    "percentual = round(listaDeputados.value_counts(normalize=True)*100,2)\n",
    "matriz = {'Número':numero,'Percentual':percentual}\n",
    "stats_geral = pd.DataFrame(data=matriz)\n",
    "moda_geral = listaDeputados_F.groupby('new').agg(lambda x: x.mode())\n",
    "info_geral = listaDeputados_F.groupby('new').agg(lambda x: x.value_counts().index[0] + f\"\\n({x.value_counts().iloc[0]} || {round(x.value_counts().iloc[0]/len(x)*100,2)}%)\")\n",
    "# moda_geral.transpose()\n",
    "# info_geral.transpose().to_clipboard()\n",
    "info_geral.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf13ff5-47c4-4401-879a-617907472bb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 - Cria a tabela de características dos deputados gaúchos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada73c2-c84c-4c84-b018-c0ddce11f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero = listaDeputados_rs.value_counts()\n",
    "percentual = round(listaDeputados_rs.value_counts(normalize=True)*100,2)\n",
    "matriz = {'Número':numero,'Percentual':percentual}\n",
    "stats_rs = pd.DataFrame(data=matriz)\n",
    "moda_rs = listaDeputados_rs.groupby('new').agg(lambda x: x.mode())\n",
    "\n",
    "info_rs = listaDeputados_rs.groupby('new').agg(lambda x: x.value_counts().index[0] + f\"\\n({x.value_counts().iloc[0]} || {round(x.value_counts().iloc[0]/len(x)*100,2)}%)\")\n",
    "\n",
    "info_rs.transpose().to_clipboard()\n",
    "# info_rs.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4348e-e033-4487-93f5-e37bafadf70a",
   "metadata": {},
   "source": [
    "## 1.5 - Gera gráfico de deputados por estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206adcc-8c0f-444e-b95f-39c4c20d27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deputados_estados = listaDeputados['ESTADO_ELEICAO'].value_counts().sort_values( ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "# deputados_estados = pd.DataFrame(list(zip(titulos,duracao)), index=titulos).sort_values(0, ascending=False)\n",
    "                            \n",
    "                            \n",
    "top = deputados_estados.plot(kind='barh', \n",
    "                        colormap='tab10', \n",
    "                        figsize=(11, 8),width=0.8)\n",
    "\n",
    "for i, v in enumerate(list(deputados_estados)):\n",
    "    top.text(v+0.4, i-0.25, v ,fontsize=12, color='black')\n",
    "\n",
    "plt.tick_params(axis='y', which='major', labelsize=14)\n",
    "    \n",
    "# top.margins(x=1)\n",
    "# top.spines['right'].set_visible(False)\n",
    "# top.spines['top'].set_visible(False)\n",
    "# top.spines['bottom'].set_visible(False)\n",
    "    \n",
    "# top.get_legend().remove()            \n",
    "\n",
    "# plt.rcParams.update(IPython_default);\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.grid(color='b', linestyle='-', linewidth=.1)    \n",
    "plt.savefig(\"novos-graficos/Figura x - Quantidade de Deputados Federais por Estado.jpg\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed466fc-8669-4df4-808b-ae469875e051",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 - Consistência Temática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cff06-a41a-4174-8657-63e901720f4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 - Carrega bases de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e74a9e-747f-46c2-baff-3ca10b649d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('max_columns', None)\n",
    "listaDeputados = pd.read_csv(\"db-listaDeputados.csv\")\n",
    "proposicoes = pd.read_csv(\"db-proposicoes.csv\")\n",
    "tweetsDeputados = pd.read_csv(\"tweetsDeputados.csv\", sep=\";\")\n",
    "\n",
    "\n",
    "\n",
    "# tweetsDeputados_100 = pd.read_csv(\"tweetsDeputados-T100.csv\", sep=\";\")\n",
    "# grafo_mt = pd.read_csv(\"grafo-mt.csv\")\n",
    "# grafo_rt = pd.read_csv(\"grafo-rt.csv\")\n",
    "# grafo_hashtags = pd.read_csv(\"grafo-hashtags.csv\")\n",
    "# grafo_semantico = pd.read_csv(\"grafo-semantico-T100.csv\")\n",
    "\n",
    "# print(listaDeputados.columns)\n",
    "# listaDeputados.head(3)\n",
    "# list(proposicoes.columns)\n",
    "# # proposicoes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9b45b-5ceb-40a3-80e8-17205ac7a8a1",
   "metadata": {},
   "source": [
    "## 2.2 - Cria base de dados da autoria das proposições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca5ce2-7564-46d2-a312-1e29dc99d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "PLs = pd.DataFrame(proposicoes[proposicoes['DESC_PROPOSICAO']=='Projeto de Lei'][proposicoes[\"TIPO_AUTOR\"]==\"Deputado\"])\n",
    "# proposicoes.shape[0]\n",
    "# PLs.shape[0]\n",
    "# list(PLs.columns)\n",
    "# PLs.head(3)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = PLs['NOME_AUTOR'].astype('str').str.split(',').map(len)\n",
    "# PLs.shape[0]\n",
    "# lens\n",
    "autores = pd.DataFrame({\n",
    "    'NOME_AUTOR': chainer(PLs['NOME_AUTOR'].astype(\"str\")), \n",
    "    'ID_AUTOR': np.repeat(PLs['ID_AUTOR'], lens),\n",
    "    'TITULO_PROPOSICAO': np.repeat(PLs['TITULO_PROPOSICAO'], lens),\n",
    "    'TEMA': np.repeat(PLs['TEMA'], lens),\n",
    "    'PALAVRAS_CHAVE': np.repeat(PLs['PALAVRAS_CHAVE'], lens),\n",
    "    'EMENTA': np.repeat(PLs['EMENTA'], lens),\n",
    "    'DATA_APRESENTACAO': np.repeat(PLs['DATA_APRESENTACAO'], lens),\n",
    "    'DESC_TRAMITACAO': np.repeat(PLs['DESC_TRAMITACAO'], lens),\n",
    "    'DESC_SITUACAO': np.repeat(PLs['DESC_SITUACAO'], lens),\n",
    "    'ID_PROPOSICAO': np.repeat(PLs['ID_PROPOSICAO'], lens),\n",
    "    'PROPOSICAO_BASE': np.repeat(PLs['PROPOSICAO_BASE'], lens),\n",
    "    'URL_PROPOSICOES': np.repeat(PLs['URL_PROPOSICOES'], lens),\n",
    "    'TEOR_URL': np.repeat(PLs['TEOR_URL'], lens)\n",
    "})\n",
    "# autores.shape[0]\n",
    "# autores.reset_index(level=0, inplace=True)\n",
    "# autores.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e9ae5-119b-47a6-a494-621cd66acba3",
   "metadata": {},
   "source": [
    "### 2.3 - Conta e agrupa proposições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043456f8-be5d-4ad6-b926-42fd1d60950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autores['N_PLS'] = 1\n",
    "\n",
    "autores_G = autores.astype(\"str\").groupby([\"NOME_AUTOR\"],as_index=False).agg({\n",
    "    'NOME_AUTOR': \"first\",\n",
    "    'N_PLS': 'count',\n",
    "    'TITULO_PROPOSICAO':lambda tags: ','.join(tags),\n",
    "    'TEMA':lambda tags: ','.join(tags),\n",
    "    'PALAVRAS_CHAVE':lambda tags: ','.join(tags),\n",
    "    'EMENTA':lambda tags: ','.join(tags),\n",
    "    'DATA_APRESENTACAO':lambda tags: ','.join(tags),\n",
    "    'DESC_TRAMITACAO':lambda tags: ','.join(tags),\n",
    "    'DESC_SITUACAO':lambda tags: ','.join(tags),\n",
    "    'ID_AUTOR': \"first\",\n",
    "    'ID_PROPOSICAO':lambda tags: ','.join(tags),\n",
    "    'PROPOSICAO_BASE':lambda tags: ','.join(tags),\n",
    "    'URL_PROPOSICOES':lambda tags: ','.join(tags),\n",
    "    'TEOR_URL':lambda tags: ','.join(tags)\n",
    "})\n",
    "\n",
    "# autores_G['ID_AUTOR'].replace('', np.nan, inplace=True)\n",
    "# autores_G.reset_index(level=0, inplace=True)\n",
    "\n",
    "# autores_G['index1'] = autores_G.index\n",
    "\n",
    "# autores_G.reset_index(level=0, inplace=True)\n",
    "# autores_G.shape[0]\n",
    "# autores_G.head(4)\n",
    "\n",
    "keepCol = ['NM_URNA','GENERO', 'COR_RACA', 'ESTADO_CIVIL','ESCOLARIDADE', 'OCUPACAO_ANTERIOR','FAIXA_ETARIA','PARTIDO_ATUAL', 'IDEOLOGIA_PARTIDO_ATUAL','MILIONARIO','ESTADO_ELEICAO','REGIAO_ELEICAO','ST_REELEICAO', 'AGRUPAMENTO_IDADE','AGRUPAMENTO_BENS','AGRUPAMENTO_VOTOS','AGRUPAMENTO_SEGUIDORES', 'AGRUPAMENTO_BALANCO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS', 'AGRUPAMENTO_BALANCO_TWEETS','ID_CAMARA','TEM_TWITTER','PERFIL_TWITTER','TOP_BTWEETS','TOP_BSEG','TOP_TWEETS','TOP_SEG','TOP_VOTACAO','TOP_BENS']\n",
    "\n",
    "listaDeputados_F = listaDeputados[keepCol]\n",
    "\n",
    "deputados_f = pd.DataFrame(listaDeputados_F[listaDeputados_F['TEM_TWITTER']=='S'])\n",
    "# twitter_f.shape[0]\n",
    "\n",
    "autores_proposicoes = pd.merge(autores_G.astype(\"str\"), deputados_f.astype(\"str\"), how='inner', left_on=['NOME_AUTOR'], right_on=['NM_URNA'])\n",
    "# autores_proposicoes = autores_proposicoes.dropna()\n",
    "# autores_proposicoes.shape[0]\n",
    "# autores_proposicoes = autores_proposicoes.drop(['SG_PARTIDO', 'SG_UF'],axis=1)\n",
    "# autores_proposicoes.head(3)\n",
    "# autores_proposicoes.shape[0]\n",
    "# autores_proposicoes.to_csv(\"autoresProposicoes.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435757a1-b12b-419f-b4f7-5359fc9e9941",
   "metadata": {},
   "source": [
    "## 2.4 - Cria base de dados dos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc9729-d9be-489f-b7c5-72d9771876ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets2020 = pd.DataFrame(tweetsDeputados[tweetsDeputados['coleta']=='C1'])\n",
    "rt = ~tweets2020['text'].str.startswith('RT @')\n",
    "\n",
    "tweets2020 = tweets2020[rt]\n",
    "\n",
    "# list(tweetsDeputados.columns)\n",
    "# tweetsDeputados.head(3)\n",
    "tweets2020.to_csv(\"tweets2020.csv\")\n",
    "\n",
    "# csv.field_size_limit(sys.maxsize)\n",
    "arq_csv = \"tweets2020.csv\"\n",
    "\n",
    "f = open(\"stopwords.txt\", 'r', encoding='utf-8')\n",
    "stopwords = [name.rstrip().lower() for name in f]\n",
    "\n",
    "with open(arq_csv, encoding=\"utf-8\") as f:\n",
    "    vTweets = [row[\"text\"] for row in DictReader(f)]\n",
    "\n",
    "vFrases = []\n",
    "\n",
    "for idx,tweet in enumerate(vTweets):\n",
    "    tweet = re.sub(r\"https?:\\/\\/(\\S+)\", \"\", unidecode(tweet))\n",
    "    # tira toda a pontuação exceto arroba e jogo da velha\n",
    "    # tweet = re.sub(r\"[^\\P{P}@#]+\", \"\", tweet)\n",
    "    # tira toda a pontuação\n",
    "    tweet = re.sub(r'[^\\w\\s]',' ',tweet)\n",
    "    tweet = \" \".join([x for x in tweet.split(' ') if x.lower() not in stopwords])\n",
    "    tweet = tweet.rstrip() \n",
    "    tweet = tweet.strip() \n",
    "    tweet = tweet.lower()   \n",
    "    vFrases.append(tweet) \n",
    "# vFrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbd9174-0331-4dfa-8f2d-5b7ed798bdf9",
   "metadata": {},
   "source": [
    "### 2.5 - Agrupa tweets com médias de rts e curtidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d0250-d2cb-4b8c-a182-11cc8f24c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets2020['TWEET_KEYWORDS'] = vFrases\n",
    "tweets2020['media_retweets'] = tweets2020['retweet_count']\n",
    "tweets2020['soma_retweets'] = tweets2020['retweet_count']\n",
    "tweets2020['media_fav'] = tweets2020['favorite_count']\n",
    "tweets2020['soma_fav'] = tweets2020['favorite_count']\n",
    "\n",
    "tweets2020['count'] = 1\n",
    "\n",
    "# tweets2020.tail(3)\n",
    "\n",
    "tweets2020_G = tweets2020.groupby([\"screen_name\"],as_index=False).agg({\n",
    "    'id': \"first\",\n",
    "    'screen_name': \"first\",\n",
    "    'text':lambda tags: ','.join(tags),\n",
    "    'TWEET_KEYWORDS':lambda tags: ','.join(tags),\n",
    "    'count': 'sum',\n",
    "    'media_retweets':'mean',\n",
    "    'soma_retweets':'sum',\n",
    "    'media_fav':'mean',\n",
    "    'soma_fav':'sum',\n",
    "    'created_at':lambda tags: ','.join(tags),\n",
    "    'media_type':lambda tags: ','.join(tags),\n",
    "    'lang':lambda tags: ','.join(tags),\n",
    "    'coleta':'first'\n",
    "})\n",
    "\n",
    "tweets2020_G['media_retweets'] = tweets2020_G['media_retweets'].round(0)\n",
    "tweets2020_G['media_fav'] = tweets2020_G['media_fav'].round(0)\n",
    "\n",
    "# tweets2020_G.shape[0]\n",
    "# tweets2020_G.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec582aa1-1455-4d39-8a0e-6dedd3249271",
   "metadata": {},
   "source": [
    "## 2.6 - Combina bancos de dados de proposicções e tweets e formata rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfffbf7-ca35-4d4e-98f4-fb034824c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_proposicoes = pd.merge(autores_proposicoes,tweets2020_G, how='inner', left_on=['PERFIL_TWITTER'], right_on=['screen_name'])\n",
    "\n",
    "# usuarios_proposicoes.reset_index(level=0, inplace=True)\n",
    "\n",
    "usuarios_proposicoes = usuarios_proposicoes.rename(columns={'id':'TWEET_IDS','text':'TEXT', 'count':'TWEET_COUNTS', 'media_retweets':'MEDIA_RETWEETS', 'soma_retweets':'SOMA_RETWEETS', 'media_fav':'MEDIA_FAV', 'soma_fav':'SOMA_FAV', 'created_at':'CREATED_AT', 'media_type':'MEDIA_TYPE', 'lang':'LANG', 'coleta':'COLETA','screen_name':'SCREEN_NAME','PALAVRAS_CHAVE':'PLS_KEYWORDS'})\n",
    "\n",
    "usuarios_proposicoes = usuarios_proposicoes.drop(['PERFIL_TWITTER'],axis=1)\n",
    "\n",
    "# list(usuarios_proposicoes.columns)\n",
    "# usuarios_proposicoes.shape[0]\n",
    "\n",
    "# usuarios_proposicoes['PALAVRAS_CHAVE'] = usuarios_proposicoes['PALAVRAS_CHAVE'].astype(\"str\").apply(lambda x: ','.join(set(x.split(','))))\n",
    "\n",
    "# usuarios_proposicoes['TWEET_KEYWORDS'] = usuarios_proposicoes['TWEET_KEYWORDS'].astype(\"str\").apply(lambda x: ','.join(set(x.split(','))))\n",
    "\n",
    "usuarios_proposicoes['PLS_KEYWORDS'] = usuarios_proposicoes['PLS_KEYWORDS'].str.replace(\",\", \" \")\n",
    "usuarios_proposicoes['TWEET_KEYWORDS'] = usuarios_proposicoes['TWEET_KEYWORDS'].str.replace(\",\", \" \")\n",
    "# usuarios_proposicoes.head(3)\n",
    "\n",
    "usuarios_proposicoes.to_csv(\"usuariosProposicoes.csv\")\n",
    "\n",
    "\n",
    "# usuarios_proposicoes = pd.read_csv(\"usuariosProposicoes.csv\")\n",
    "# usuarios_proposicoes.shape[0]\n",
    "\n",
    "# usuarios_proposicoes.shape[0]\n",
    "# usuarios_proposicoes = usuarios_proposicoes.dropna()\n",
    "# usuarios_proposicoes.shape[0]\n",
    "\n",
    "# usuarios_proposicoes.to_csv(\"usuariosProposicoes.csv\")\n",
    "\n",
    "# usuarios_proposicoes = usuarios_proposicoes.dropna()\n",
    "# usuarios_proposicoes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3253150-b47c-4d50-ae92-45a4bea56151",
   "metadata": {},
   "source": [
    "## 2.7 - Gera gráfico da proporção de Deputados Federais que submeteram proposições e publicaram tweets em 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021da91-b547-4d18-9be7-b62431f6588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = percentual.plot(kind='barh', \n",
    "                        colormap='tab10', \n",
    "                        figsize=(11, 8),width=0.8)\n",
    "\n",
    "for i, v in enumerate(list(percentual)):\n",
    "    top.text(v+0.4, i-0.25, str(v)+\"%\" ,fontsize=12, color='black')\n",
    "\n",
    "plt.tick_params(axis='y', which='major', labelsize=14)\n",
    "    \n",
    "# top.margins(x=1)\n",
    "top.spines['right'].set_visible(False)\n",
    "# top.spines['top'].set_visible(False)\n",
    "# top.spines['bottom'].set_visible(False)\n",
    "    \n",
    "# top.get_legend().remove()            \n",
    "\n",
    "# plt.rcParams.update(IPython_default);\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.grid(color='b', linestyle='-', linewidth=.1)    \n",
    "plt.savefig(\"novos-graficos/Figura x - Proporção de Deputados Federais que submeteram proposições e publicaram tweets em 2020.jpg\",bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f4f48-38de-4447-8f7c-9321008ef744",
   "metadata": {},
   "source": [
    "## 2.8 - Cria índice de consistência temática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8d865-617e-4b4a-a2da-185545f0ee35",
   "metadata": {},
   "source": [
    "### 2.9 - Remove stop words das proposições </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce11714-c3ab-48e0-946e-b294fe643f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywordsCamara = usuarios_proposicoes['PLS_KEYWORDS'].astype(\"str\").values.tolist()\n",
    "# usuarios_proposicoes['PLS_KEYWORDS'].shape[0]\n",
    "# len(keywordsCamara)\n",
    "# len(keywordsTwitter)\n",
    "# keywordsCamara[0]\n",
    "\n",
    "f = open(\"stopwords.txt\", 'r', encoding='utf-8')\n",
    "stopwords = [name.rstrip().lower() for name in f]\n",
    "vCamara = []\n",
    "vCamara1 = []\n",
    "\n",
    "\n",
    "for frase in keywordsCamara:\n",
    "    frase = re.sub(r'[^\\w\\s]','',unidecode(frase))\n",
    "    frase = re.sub(r'\\n_',' ',frase)\n",
    "    frase = re.sub(r'\\n',' ',frase)\n",
    "    frase = re.sub(r'_',' ',frase)\n",
    "    # frase = re.sub(r' sobre | qualquer | das | da | dos | do | de | e | a | o | para | com | em | ou | à | na | no ',' ',frase)\n",
    "    frase = \" \".join([x for x in frase.split(' ') if x.lower() not in stopwords])\n",
    "    frase = frase.replace(\" do \",\"\")\n",
    "    frase = frase.lower()\n",
    "    frase = frase.replace(\"    \",\"   \")\n",
    "    frase = frase.replace(\"   \",\"  \")\n",
    "    frase = frase.replace(\"  \",\" \")\n",
    "    frase = frase.strip()\n",
    "    vCamara1.append(frase)\n",
    "    vfrases1 = frase.split(' ')\n",
    "    vfrases2 = []\n",
    "    for x in vfrases1:\n",
    "        if x not in vfrases2 and x != '':\n",
    "            vfrases2.append(x)\n",
    "    vCamara.append(vfrases2)\n",
    "    \n",
    "    \n",
    "# usuarios_proposicoes['PLS_KEYWORDS'].shape[0]\n",
    "# len(vCamara)\n",
    "\n",
    "# oe = 50\n",
    "\n",
    "# len(vCamara[oe])\n",
    "# vCamara[oe]\n",
    "# len(vCamara1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3051059-347d-4436-8b23-0386955664ed",
   "metadata": {},
   "source": [
    "### 2.10 - Remove stop words dos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdff51f-fcee-4d6d-8fd4-289fd1eff256",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsTwitter = usuarios_proposicoes['TWEET_KEYWORDS'].astype(\"str\").values.tolist()\n",
    "\n",
    "vTwitter = []\n",
    "\n",
    "for frase in keywordsTwitter:\n",
    "    # frase = re.sub(r'[^\\w\\s]','',frase)\n",
    "    frase = re.sub(r'\\n',' ',unidecode(frase))\n",
    "    frase = frase.replace(\"   \",\"  \")\n",
    "    frase = frase.replace(\"  \",\" \")\n",
    "    # # frase = \" \".join([x for x in tweet.split(' ') if x.lower() not in stopwords])\n",
    "    # frase = frase.lower()\n",
    "    frase = \" \".join([x for x in frase.split(' ') if x.lower() not in stopwords])\n",
    "    frase = frase.strip()\n",
    "    # vTwitter.append(unidecode(frase).split(' '))\n",
    "    vfrases1 = unidecode(frase).split(' ')\n",
    "    vfrases2 = []\n",
    "    for x in vfrases1:\n",
    "        if x not in vfrases2:\n",
    "            vfrases2.append(x)\n",
    "    vTwitter.append(vfrases2)\n",
    "\n",
    "    \n",
    "    \n",
    "# usuarios_proposicoes['TWEET_KEYWORDS'].head(3)\n",
    "# usuarios_proposicoes['TWEET_KEYWORDS'].shape[0]\n",
    "len(vTwitter[0])\n",
    "# vTwitter[0]\n",
    "\n",
    "# usuarios_proposicoes = pd.read_csv(\"usuariosProposicoes.csv\")\n",
    "# usuarios_proposicoes.to_csv(\"usuariosProposicoes.csv\",index=False)\n",
    "\n",
    "# usuarios_proposicoes = usuarios_proposicoes.dropna()\n",
    "# usuarios_proposicoes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393c6200-d6fb-45ac-866f-0b7c05a68682",
   "metadata": {},
   "source": [
    "### 2.11 - Faz a interseção entre tweets e propostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9f64d-5e4c-4e79-869c-d5db53538f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "somaLista = []\n",
    "for x,y in zip(vCamara, vTwitter):\n",
    "    somaLista.append(x+y)\n",
    "\n",
    "# len(vTwitter[0])\n",
    "# len(vCamara[0])\n",
    "# len(somaLista[0])\n",
    "\n",
    "uniaoLista = []\n",
    "\n",
    "for lista in somaLista:\n",
    "    vUnicos = []\n",
    "    for palavra in lista:\n",
    "        if palavra not in vUnicos:\n",
    "            vUnicos.append(palavra)\n",
    "    uniaoLista.append(vUnicos)\n",
    "        \n",
    "# somaLista[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdc2f5-14aa-4c06-90e1-8ff4eefc759a",
   "metadata": {},
   "source": [
    "### 2.12 - Mede a semelhança entre conteúdo dos tweets e das proposições e cria rótulos a partir dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206688f-f6c8-4ea8-8da3-bd601c7d9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecao = [ (set.intersection(set(x), set(y))) for x,y in zip(vCamara, vTwitter)]\n",
    "cTematica = [ (round(len(x)/len(y)*100,2)) for x,y in zip(intersecao,vCamara)]\n",
    "\n",
    "# len(cTematica)\n",
    "# usuarios_proposicoes.shape[0]\n",
    "\n",
    "# teste1 = cTematica.dropna()\n",
    "# len(teste1)\n",
    "\n",
    "# print(type(cTematica))\n",
    "# len(cTematica2)\n",
    "\n",
    "usuarios_proposicoes['CONSISTENCIA_TEMATICA'] = cTematica\n",
    "usuarios_proposicoes['INTERSECAO'] = intersecao\n",
    "usuarios_proposicoes.to_csv(\"usuariosProposicoes.csv\", index=False)\n",
    "# teste = usuarios_proposicoes[['NM_URNA','CONSISTENCIA_TEMATICA']]\n",
    "# teste.shape[0]\n",
    "# teste.sort_values(by='CONSISTENCIA_TEMATICA', ascending=False)\n",
    "# teste = teste.dropna()\n",
    "# usuarios_proposicoes\n",
    "\n",
    "faixa = ['cTEMATICA_G1','cTEMATICA_G2','cTEMATICA_G3','cTEMATICA_G4']\n",
    "usuarios_proposicoes['AGRUPAMENTO_cTEMATICA'] = pd.qcut(usuarios_proposicoes['CONSISTENCIA_TEMATICA'],4,precision=0,labels=faixa)\n",
    "# qcut = usuarios_proposicoes.groupby('AGRUPAMENTO_cTEMATICA').agg(lambda x: x.mode())\n",
    "# qcut\n",
    "\n",
    "# d2g.upload(usuarios_proposicoes, spreadsheet_key, 'usuariosProposicoes', credentials=credentials, row_names=True)\n",
    "\n",
    "# quase tagcloud\n",
    "# y = [(x, vCamara[0].count(x)) for x in set(vCamara[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f548ad-14b9-40d4-b21d-edd59a437fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuarios_proposicoes.columns\n",
    "# usuarios_proposicoes2 = usuarios_proposicoes.drop(['TEXT','EMENTA','URL_PROPOSICOES','TEOR_URL','CREATED_AT','DATA_APRESENTACAO', 'DESC_TRAMITACAO', 'DESC_SITUACAO','ID_AUTOR', 'ID_PROPOSICAO', 'PROPOSICAO_BASE','PLS_KEYWORDS','TWEET_KEYWORDS','NM_URNA'], axis=1)\n",
    "# d2g.upload(usuarios_proposicoes2, spreadsheet_key, 'usuariosProposicoes', credentials=credentials, row_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df72bad-4752-441a-8029-f8b2c652096b",
   "metadata": {},
   "source": [
    "### 2.13 - Calcula a média geral de consistência temática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169d41a-8f71-479a-b5fe-abb0804bc710",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_genero = usuarios_proposicoes.groupby([\"GENERO\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_genero['CATEGORIA'] = \"GENERO\"\n",
    "ct_raca = usuarios_proposicoes.groupby([\"COR_RACA\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_raca['CATEGORIA'] = \"COR_RACA\"\n",
    "ct_estadoCivil = usuarios_proposicoes.groupby([\"ESTADO_CIVIL\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_estadoCivil['CATEGORIA'] = \"ESTADO_CIVIL\"\n",
    "ct_escolaridade = usuarios_proposicoes.groupby([\"ESCOLARIDADE\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_escolaridade['CATEGORIA'] = \"ESCOLARIDADE\"\n",
    "ct_ocupacao = usuarios_proposicoes.groupby([\"OCUPACAO_ANTERIOR\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ocupacao['CATEGORIA'] = \"OCUPACAO_ANTERIOR\"\n",
    "ct_partido = usuarios_proposicoes.groupby([\"PARTIDO_ATUAL\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_partido['CATEGORIA'] = \"PARTIDO_ATUAL\"\n",
    "ct_ideologia = usuarios_proposicoes.groupby([\"IDEOLOGIA_PARTIDO_ATUAL\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ideologia['CATEGORIA'] = \"IDEOLOGIA_PARTIDO_ATUAL\"\n",
    "ct_milionario = usuarios_proposicoes.groupby([\"MILIONARIO\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_milionario['CATEGORIA'] = \"MILIONARIO\"\n",
    "ct_estado = usuarios_proposicoes.groupby([\"ESTADO_ELEICAO\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_estado['CATEGORIA'] = \"ESTADO_ELEICAO\"\n",
    "ct_regiao = usuarios_proposicoes.groupby([\"REGIAO_ELEICAO\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_regiao['CATEGORIA'] = \"REGIAO_ELEICAO\"\n",
    "ct_reeleito = usuarios_proposicoes.groupby([\"ST_REELEICAO\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_reeleito['CATEGORIA'] = \"ST_REELEICAO\"\n",
    "ct_ag_idade = usuarios_proposicoes.groupby([\"AGRUPAMENTO_IDADE\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_idade['CATEGORIA'] = \"AGRUPAMENTO_IDADE\"\n",
    "ct_ag_bens = usuarios_proposicoes.groupby([\"AGRUPAMENTO_BENS\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_bens['CATEGORIA'] = \"AGRUPAMENTO_BENS\"\n",
    "ct_ag_votos = usuarios_proposicoes.groupby([\"AGRUPAMENTO_VOTOS\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_votos['CATEGORIA'] = \"AGRUPAMENTO_VOTOS\"\n",
    "ct_ag_seguidores = usuarios_proposicoes.groupby([\"AGRUPAMENTO_SEGUIDORES\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_seguidores['CATEGORIA'] = \"AGRUPAMENTO_SEGUIDORES\"\n",
    "ct_ag_bseguidores = usuarios_proposicoes.groupby([\"AGRUPAMENTO_BALANCO_SEGUIDORES\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_bseguidores['CATEGORIA'] = \"AGRUPAMENTO_BALANCO_SEGUIDORES\"\n",
    "ct_ag_tweets = usuarios_proposicoes.groupby([\"AGRUPAMENTO_NUMERO_TWEETS\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_tweets['CATEGORIA'] = \"AGRUPAMENTO_NUMERO_TWEETS\"\n",
    "ct_ag_btweets = usuarios_proposicoes.groupby([\"AGRUPAMENTO_BALANCO_TWEETS\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "ct_ag_btweets['CATEGORIA'] = \"AGRUPAMENTO_BALANCO_TWEETS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb22032-26ea-43ba-8c8b-91563240f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistencia_tematica = pd.concat([ct_genero, ct_raca, ct_estadoCivil, ct_escolaridade, ct_partido, ct_ideologia, ct_milionario, ct_estado, ct_regiao, ct_reeleito, ct_ag_idade, ct_ag_bens, ct_ag_votos, ct_ag_seguidores, ct_ag_bseguidores, ct_ag_tweets, ct_ag_btweets, ct_ocupacao])\n",
    "\n",
    "consistencia_tematica['CONSISTENCIA_TEMATICA'].mean()\n",
    "# consistencia_tematica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e1341-7694-4b6b-9911-ce63392ab6a4",
   "metadata": {},
   "source": [
    "### 2.14 - Calcula a média de consistência temática por estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cdcdac-34e1-44e4-bd65-297b9288bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_estado = usuarios_proposicoes.groupby([\"ESTADO_ELEICAO\"]).agg({'CONSISTENCIA_TEMATICA':'mean'})\n",
    "\n",
    "ct_estado['CONSISTENCIA_TEMATICA'] = ct_estado['CONSISTENCIA_TEMATICA'].round(2)\n",
    "\n",
    "ct_estado['CONSISTENCIA_TEMATICA'].mean()\n",
    "\n",
    "\n",
    "# ct_estado\n",
    "# print(type(ct_estado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de0fe1-4553-470a-881d-fa0f19fd46b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(usuarios_proposicoes.columns)\n",
    "usuarios_proposicoes['N_PLS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b971b48-d6ac-4e48-be1f-47b764be920e",
   "metadata": {},
   "source": [
    "### 2.15 - Gera gráfico com número de tweets por Estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7d10aa-c221-44ce-9480-f9c21e9bcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_estado = usuarios_proposicoes.groupby([\"ESTADO_ELEICAO\"]).agg({'TWEET_COUNTS':'sum'})\n",
    "\n",
    "t_estado = t_estado.sort_values(by='TWEET_COUNTS', ascending=True)\n",
    "\n",
    "total = t_estado['TWEET_COUNTS']\n",
    "total\n",
    "\n",
    "# ct_estado\n",
    "# print(type(ct_estado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0c84c-923e-4a9d-b29b-8f26cf974433",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        \n",
    "top = total.plot(kind='barh', \n",
    "                        colormap='tab10', \n",
    "                        figsize=(12, 8),width=0.8)\n",
    "\n",
    "for i, v in enumerate(list(total)):\n",
    "    top.text(v+0.4, i-0.25, v ,fontsize=12, color='black')\n",
    "\n",
    "plt.tick_params(axis='y', which='major', labelsize=14)\n",
    "    \n",
    "# top.margins(x=1)\n",
    "# top.spines['right'].set_visible(False)\n",
    "# top.spines['top'].set_visible(False)\n",
    "# top.spines['bottom'].set_visible(False)\n",
    "    \n",
    "# top.get_legend().remove()            \n",
    "top.set_ylabel('')\n",
    "# plt.rcParams.update(IPython_default);\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.grid(color='b', linestyle='-', linewidth=.1)    \n",
    "plt.savefig(\"novos-graficos/Figura x - Quantidade de Tweets por Estado.jpg\",bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a44e77-d4f8-4d1c-b51b-48f4eedf4508",
   "metadata": {},
   "source": [
    "### 2.16 - Cria tabela com as médias de consistência temática por estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53bfeb5-6ead-4619-86f8-ec9007b8ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "faixa = ['G4','G3','G2','G1']\n",
    "ct_estado['AGRUPAMENTO'] = pd.qcut(ct_estado['CONSISTENCIA_TEMATICA'],4,precision=0,labels=faixa)\n",
    "\n",
    "\n",
    "ct_estado = ct_estado.sort_values(['CONSISTENCIA_TEMATICA'], ascending=[False])\n",
    "\n",
    "\n",
    "ct_estado.to_csv(\"consistenciaTematica-estados.csv\", index=False)\n",
    "\n",
    "ct_estado\n",
    "# qcut = usuarios_proposicoes.groupby('AGRUPAMENTO_cTEMATICA').agg(lambda x: x.mode())\n",
    "# qcut\n",
    "\n",
    "# d2g.upload(ct_estado, spreadsheet_key, 'consistenciaTematica', credentials=credentials, row_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb121377-dc69-4483-8652-f46b75ee5c5f",
   "metadata": {},
   "source": [
    "### 2.17 - Salva resultados em arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdbbcb4-eaa7-41cb-98d4-15b9a3cd1a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# usuarios_proposicoes.shape[0]\n",
    "# len(vCamara)\n",
    "# len(vTwitter)\n",
    "\n",
    "usuarios_proposicoes['PLS_KEYWORDS'] = vCamara\n",
    "usuarios_proposicoes['TWEET_KEYWORDS'] = vTwitter\n",
    "\n",
    "\n",
    "usuarios_proposicoes['PLS_KEYWORDS'] = usuarios_proposicoes['PLS_KEYWORDS'].astype(str).str.replace(',',' ')\n",
    "usuarios_proposicoes['PLS_KEYWORDS'] = usuarios_proposicoes['PLS_KEYWORDS'].astype(str).str.replace('[^\\w\\s]','')\n",
    "\n",
    "\n",
    "\n",
    "usuarios_proposicoes['TWEET_KEYWORDS'] = usuarios_proposicoes['TWEET_KEYWORDS'].astype(str).str.replace(',',' ')\n",
    "usuarios_proposicoes['TWEET_KEYWORDS'] = usuarios_proposicoes['TWEET_KEYWORDS'].astype(str).str.replace('[^\\w\\s]','')\n",
    "\n",
    "\n",
    "usuarios_proposicoes['INTERSECAO'] = usuarios_proposicoes['INTERSECAO'].astype(str).str.replace(',',' ')\n",
    "usuarios_proposicoes['INTERSECAO'] = usuarios_proposicoes['INTERSECAO'].astype(str).str.replace('[^\\w\\s]','')\n",
    "\n",
    "\n",
    "\n",
    "# usuarios_proposicoes.head(2)\n",
    "\n",
    "usuarios_proposicoes.to_csv(\"usuarios_proposicoes-2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0203c2-2114-48e4-bbc0-4962cd709567",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.18 - Gera gráficos gerais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e448a7-0593-4739-b186-0d8e1d327994",
   "metadata": {},
   "source": [
    "### 2.19 - Maiores e menores índices de consistência temática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c86923-d40d-429e-8023-144b677532b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_estado = ct_estado.drop('AGRUPAMENTO', 1)\n",
    "ct_estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11afbe5-c29c-4e1d-a7d0-9e6ec5ac4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptop10 = ct_estado.nlargest(12,'CONSISTENCIA_TEMATICA').sort_values(by='CONSISTENCIA_TEMATICA', ascending=True)\n",
    "indices1  = ptop10.apply(lambda row: str(row.CONSISTENCIA_TEMATICA) +\"%\", axis=1)\n",
    "indices1 = list(indices1)\n",
    "ptop10 = ptop10['CONSISTENCIA_TEMATICA']\n",
    "\n",
    "pbottom10 = ct_estado.nsmallest(15,'CONSISTENCIA_TEMATICA').sort_values(by='CONSISTENCIA_TEMATICA', ascending=True)\n",
    "\n",
    "indices2  = pbottom10.apply(lambda row: str(row.CONSISTENCIA_TEMATICA) +\"%\", axis=1)\n",
    "# indices2 = list(pbottom10['CONSISTENCIA_TEMATICA'])\n",
    "indices2 = list(indices2)\n",
    "pbottom10 = pbottom10['CONSISTENCIA_TEMATICA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251ce31-0c3d-4950-8bbd-985c86812677",
   "metadata": {},
   "outputs": [],
   "source": [
    "axd = plt.figure(figsize=(8,10)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    A\n",
    "    B\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "top10 = ptop10.plot(kind='barh', \n",
    "                        color='#0A8CB1', \n",
    "                        width=0.8,ax=axd['A'])\n",
    "\n",
    "\n",
    "for i, v in enumerate(list(ptop10)):\n",
    "    top10.text(v-5, i-0.1, indices1[i], color='white',weight='heavy')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# for i, v in enumerate(list(votacoes_10)):\n",
    "#     top.text(v-20, i-0.15, indices1[i] ,fontsize=12, color='white',weight='heavy')\n",
    "\n",
    "\n",
    "\n",
    "# for i, v in enumerate(list(total)):\n",
    "#     top.text(v+0.4, i-0.25, v ,fontsize=12, color='black')\n",
    "\n",
    "# top10 = sns.barplot(color='#0A8CB1',data=ptop10,ax=axd['A'])\n",
    "# top10 = sns.barplot(color='#0A8CB1',data=ptop10)\n",
    "\n",
    "\n",
    "bottom10 = pbottom10.plot(kind='barh', \n",
    "                        color='#BC0D0D', \n",
    "                        width=0.8,ax=axd['B'])\n",
    "\n",
    "# bottom10 = sns.barplot(color='#BC0D0D',data=pbottom10,ax=axd['B'])\n",
    "\n",
    "for i, v in enumerate(list(pbottom10)):\n",
    "    bottom10.text(v-4, i-0.1, indices2[i], color='white',weight='heavy')\n",
    "    \n",
    "    \n",
    "# for i, v in enumerate(list(votacoes_10)):\n",
    "#     top.text(v-20, i-0.15, indices[i] ,fontsize=12, color='white',weight='heavy')\n",
    "\n",
    "# top10.get_legend().remove()  \n",
    "# bottom10.get_legend().remove()  \n",
    "\n",
    "top10.set_ylabel('')    \n",
    "top10.set_xlabel('')\n",
    "\n",
    "bottom10.set_ylabel('')    \n",
    "bottom10.set_xlabel('')\n",
    "\n",
    "bottom10.grid(color='b', linestyle='-', linewidth=.1)   \n",
    "top10.grid(color='b', linestyle='-', linewidth=.1)   \n",
    "\n",
    "plt.tight_layout()\n",
    "# axd\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\"novos-graficos/Figura x - Índices de consistência temática por estado.jpg\",bbox_inches = 'tight')\n",
    "plt.clf()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d6895-7405-4c8e-b50a-ef98440cab6d",
   "metadata": {},
   "source": [
    "### 2.20 - Temas e palavras-chave mais frequentes nas proposições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e526e8b-8269-45d1-845b-ebbf9af66d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vCamara2 = [item for sublist in vCamara for item in sublist]\n",
    "vCamara3 = ' '.join([str(elem) for elem in vCamara2])\n",
    "\n",
    "# if \"codigo\" in vCamara2:\n",
    "#     print(\"é ta sim\")\n",
    "# else:\n",
    "#     print(\"ta nao\")\n",
    "\n",
    "# len(vCamara2)\n",
    "# len(vCamara1)\n",
    "\n",
    "axd = plt.figure(figsize=(16,8)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    AB\n",
    "    \"\"\", \n",
    "    gridspec_kw={\n",
    "        'width_ratios': [5, 6],\n",
    "        'wspace': 0.1\n",
    "    })\n",
    "\n",
    "lang_responses = usuarios_proposicoes['TEMA']\n",
    "\n",
    "language_counter = Counter()\n",
    "    \n",
    "for response in lang_responses:\n",
    "    language_counter.update(response.split(','))\n",
    "        \n",
    "languages = []\n",
    "popularity = []\n",
    "    \n",
    "for item in language_counter.most_common(10):\n",
    "    languages.append(item[0])\n",
    "    popularity.append(item[1])\n",
    "\n",
    "# n30 = popularity[:10]\n",
    "# n30 = popularity[-30:]\n",
    "\n",
    "\n",
    "languages.reverse()\n",
    "popularity.reverse()\n",
    "\n",
    "\n",
    "axd['A'].barh(languages, popularity)\n",
    "\n",
    "# axd['A'].yticks(fontsize=28)\n",
    "axd['A'].set_yticklabels(languages,fontsize=18)\n",
    "\n",
    "for i, v in enumerate(popularity):\n",
    "    axd['A'].text(v-200, i-.07, str(v), color='white',size=17)\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    # max_font_size=80,\n",
    "    min_font_size=22,\n",
    "    max_words=15,\n",
    "    prefer_horizontal=1,\n",
    "    # scale=10,\n",
    "    height=640,\n",
    "    width=550,\n",
    "    background_color = 'white',\n",
    "    stopwords=stopwords).generate(str(vCamara3))\n",
    "\n",
    "# axd['A'].set_title('Temas',fontsize=20)\n",
    "# axd['B'].set_title('Palavras-chave',fontsize=20)\n",
    "\n",
    "axd['B'].axis('off')\n",
    "axd['B'].imshow(wordcloud, interpolation = 'bilinear')\n",
    "\n",
    "\n",
    "\n",
    "# plt.set_title('Palavras-chave',fontsize=20)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "\n",
    "# plt.tight_layout(pad=0)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.savefig(\"2 - Figura 8 - Temas e palavras-chave mais recorrentes nas proposições.jpg\",bbox_inches = 'tight')\n",
    "# plt.figure(figsize=(5,10))\n",
    "# bottom10 = sns.barplot(x=popularityr,y=languagesr, color='#0A8CB1')\n",
    "    \n",
    "\n",
    "    \n",
    "# plt.barh(languages, popularity)\n",
    "# # plt.title(\"Most popular languages\")\n",
    "# # plt.ylabel(\"Programming Languages\")\n",
    "# # plt.xlabel(\"Number of People who use\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# quase tagcloud\n",
    "# y = [(x, vCamera.count(x)) for x in set(vCamera)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b64d4-761b-486c-aecb-3f18943a04f3",
   "metadata": {},
   "source": [
    "### 2.21 - Publicações mais compartilhadas no Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed955e-a33f-45d0-82ca-72fae1a99642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tweets2020.head(2)\n",
    "topTweets = tweets2020.nlargest(3,'retweet_count')\n",
    "# tweetsTop10\n",
    "topIds = topTweets['id'].astype(\"str\").values.tolist()\n",
    "\n",
    "string = \"https://twitter.com/OReillyMedia/status/\"\n",
    "\n",
    "topIds = [string + s for s in topIds]\n",
    "# topIds\n",
    "\n",
    "class Tweet(object):\n",
    "    def __init__(self, s, embed_str=False):\n",
    "        if not embed_str:\n",
    "            # Use Twitter's oEmbed API\n",
    "            # https://dev.twitter.com/web/embedded-tweets\n",
    "            api = 'https://publish.twitter.com/oembed?url={}'.format(s)\n",
    "            response = requests.get(api)\n",
    "            self.text = response.json()[\"html\"]\n",
    "        else:\n",
    "            self.text = s\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return self.text\n",
    "\n",
    "# Tweet(\"https://twitter.com/OReillyMedia/status/1253710046405500928\")\n",
    "    \n",
    "for x in topIds:\n",
    "    Tweet(x)\n",
    "# vTweets(topIds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207caad-7677-4ac8-944e-0e2b02bd2b7b",
   "metadata": {},
   "source": [
    "<h3> 2.22 - Usuários, hashtags e palavras mais utlizadas no Twitter </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f2117-ee1d-4d9d-b499-0f629b7d50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsTwitter = usuarios_proposicoes['TWEET_KEYWORDS'].astype(\"str\").values.tolist()\n",
    "\n",
    "vTwitter1 = []\n",
    "\n",
    "f = open(\"stopwords.txt\", 'r', encoding='utf-8')\n",
    "stopwords = [name.rstrip().lower() for name in f]\n",
    "\n",
    "for tweet in keywordsTwitter:\n",
    "    tweet = re.sub(r'\\n',' ',unidecode(tweet))\n",
    "    tweet = tweet.replace(\"  \",\" \")\n",
    "    # tweet = tweet.replace(\"paraben\",\"parabens\")\n",
    "    tweet = \" \".join([x for x in tweet.split(' ') if x.lower() not in stopwords])\n",
    "    vTwitter1.append(tweet) \n",
    "# vFrases  \n",
    "\n",
    "# tweets2020['TWEET_KEYWORDS'] = vFrases\n",
    "# len(vTwitter)\n",
    "# len(vTwitter1)\n",
    "# vTwitter[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b2630-c235-46b1-88e7-dbd197ba2334",
   "metadata": {},
   "source": [
    "#### 2.23 - Extrai as informações dos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d01514-8e1e-459e-950a-f4734e30c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_repetition = 1\n",
    "hashtags_repetition = 1\n",
    "users_repetition = 1\n",
    "\n",
    "#variables for how many words, hashtags, users to display\n",
    "word_limit = 10\n",
    "hashtag_limit = 10\n",
    "user_limit = 10\n",
    "\n",
    "#file path for stopwords and json exports\n",
    "stopwords_file_path = 'stopwords.txt'\n",
    "# json_export_file_path = '1-total.json'\n",
    "\n",
    "with open(stopwords_file_path, encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "items = tweets2020.to_dict('records')\n",
    "# items[0]\n",
    "\n",
    "#taken from https://stackoverflow.com/a/49146722\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        \"\\U00002702-\\U000027B0\"\n",
    "                        \"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "#taken from https://gist.github.com/glenbot/4684356\n",
    "def sanitize_3(user_input, stop_words):\n",
    "    \"\"\"Sanitize using standard lists\"\"\"\n",
    "    new_list = []\n",
    "    for w in user_input:\n",
    "        if w not in stop_words:\n",
    "            new_list.append(w)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "#remove accents, emoji, convert to all lowercase\n",
    "for idx, item in enumerate(items):\n",
    "    items[idx]['text'] = remove_emoji(items[idx]['text'])\n",
    "    items[idx]['text'] = unidecode(items[idx]['text'])\n",
    "    items[idx]['text'] = items[idx]['text'].lower()\n",
    "    #print items[idx]['text']\n",
    "\n",
    "\n",
    "#removing stopwords\n",
    "#convert every tweet into a list of words\n",
    "#call sanitize_3 for every list of words\n",
    "current_string = ''\n",
    "placeholder_list = [None] * len(items)\n",
    "master_word_list = []\n",
    "master_hashtag_list = []\n",
    "master_user_list = []\n",
    "\n",
    "for idx, item in enumerate(items):\n",
    "    #word_list = re.sub(\"[^\\w]\", \" \", items[idx]['text']).split()\n",
    "    word_list = re.sub(r'[.!,;:?]', ' ', items[idx]['text']).split()\n",
    "    word_list = sanitize_3(word_list, stopwords)\n",
    "    for idx2, word in enumerate(word_list):\n",
    "        if word_list[idx2][:1] == '#':\n",
    "            current_string += ' ' + word_list[idx2]\n",
    "            master_hashtag_list.append(word_list[idx2])\n",
    "        elif word_list[idx2][:1] == '@':\n",
    "            current_string += ' ' + word_list[idx2]\n",
    "            master_user_list.append(word_list[idx2])\n",
    "        elif word_list[idx2][:3] == '//t':              #dirty workaround\n",
    "            pass\n",
    "        elif 'co/' not in word_list[idx2]:\n",
    "            current_string += ' ' + word_list[idx2]\n",
    "            master_word_list.append(word_list[idx2])\n",
    "    placeholder_list[idx] = current_string\n",
    "    current_string = ''\n",
    "\n",
    "\n",
    "#release memory immediately\n",
    "del placeholder_list[:]\n",
    "\n",
    "#rank words\n",
    "#adapted from https://github.com/kevinschaul/Word-Rank/blob/master/wordRank.py\n",
    "l = {}\n",
    "hashtag_dict = {}\n",
    "user_dict = {}\n",
    "\n",
    "for word in master_word_list:\n",
    "    # if word is in dictionary, increment the value\n",
    "    # otherwise add the word to dictionary with value 1\n",
    "    if word in l:\n",
    "        l[word] += 1\n",
    "    else:\n",
    "        l[word] = 1\n",
    "\n",
    "for hashtag in master_hashtag_list:\n",
    "    if hashtag in hashtag_dict:\n",
    "        hashtag_dict[hashtag] += 1\n",
    "    else:\n",
    "        hashtag_dict[hashtag] = 1\n",
    "\n",
    "for user in master_user_list:\n",
    "    if user in user_dict:\n",
    "        user_dict[user] += 1\n",
    "    else:\n",
    "        user_dict[user] = 1\n",
    "\n",
    "\n",
    "wordsV1 = []\n",
    "wordsV2 = []\n",
    "\n",
    "# this prints the dict out d by value in descending order\n",
    "count = 0\n",
    "# print('\\n#########   Printing ranking of words   #########\\n')\n",
    "for key, value in sorted(iter(l.items()), reverse=True, key=lambda k_v3: (k_v3[1],k_v3[0])):\n",
    "    if count < word_limit:\n",
    "        # print('%s: %s' % (key, value))\n",
    "        wordsV1.append(key)\n",
    "        wordsV2.append(value)\n",
    "    count+=1\n",
    "\n",
    "wordsD1 = dict(zip(wordsV1, wordsV2))\n",
    "# print(wordsD1)\n",
    "\n",
    "hashtagV1 = []\n",
    "hashtagV2 = []\n",
    "\n",
    "count = 0\n",
    "# print('\\n#########   Printing ranking of hashtags   #########\\n')\n",
    "for key, value in sorted(iter(hashtag_dict.items()), reverse=True, key=lambda k_v4: (k_v4[1],k_v4[0])):\n",
    "    if count < hashtag_limit:\n",
    "        # print('%s: %s' % (key, value))\n",
    "        hashtagV1.append(key)\n",
    "        hashtagV2.append(value)\n",
    "        \n",
    "    count +=1\n",
    "\n",
    "hashtagD1 = dict(zip(hashtagV1, hashtagV2))\n",
    "\n",
    "# print(hashtagD1)\n",
    "\n",
    "# plt.rcdefaults()\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# y_pos = np.arange(len(hashtagV1))\n",
    "# error = np.random.rand(len(hashtagV1))\n",
    "\n",
    "# ax.barh(y_pos, hashtagV2, xerr=error, align='center')\n",
    "# ax.set_yticks(y_pos)\n",
    "# ax.set_yticklabels(hashtagV1)\n",
    "# ax.invert_yaxis()  # labels read top-to-bottom\n",
    "# ax.set_xlabel('Frequência')\n",
    "# ax.set_title('Hashtags mais utilizadas')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "usersV1 = []\n",
    "usersV2 = []\n",
    "\n",
    "count = 0\n",
    "# print('\\n#########   Printing ranking of most mentioned users   #########\\n')\n",
    "for key, value in sorted(iter(user_dict.items()), reverse=True, key=lambda k_v5: (k_v5[1],k_v5[0])):\n",
    "    if count < user_limit:\n",
    "        # print('%s: %s' % (key, value))\n",
    "        usersV1.append(key)\n",
    "        usersV2.append(value)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "usersD1 = dict(zip(usersV1, usersV2))\n",
    "# print(usersD1)\n",
    "\n",
    "most_retweeted_list = []\n",
    "list_is_full = False\n",
    "\n",
    "for tweet in items:\n",
    "    if 'rt @' in tweet['text']:\n",
    "        pass\n",
    "    elif tweet['retweet_count'] > 10:\n",
    "        most_retweeted_list.append(tweet)\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "tweets =[]\n",
    "rts = []\n",
    "ids = []\n",
    "\n",
    "# print('\\n#########   Printing most retweeted tweets   #########\\n')\n",
    "for tweet in sorted(most_retweeted_list, key = lambda x: x['retweet_count'], reverse=True):\n",
    "    current_date = datetime.strptime(tweet['created_at'],'%Y-%m-%d %H:%M:%S+00:00')\n",
    "    # if (current_date.year == 2020) and (current_date.month == 11) and (current_date.day < 17):\n",
    "    tweets.append(tweet['screen_name'] +\" - \"+ tweet['text'])\n",
    "    rts.append(tweet['retweet_count'])\n",
    "    ids.append(tweet['id'])\n",
    "    if count == 20:\n",
    "        break\n",
    "    count+=1\n",
    "\n",
    "# rtKeys1 = ['tweet','rts','ids']\n",
    "# rtKeys2 =  rtKeys1 *len(ids)\n",
    "# print(rtKeys2)\n",
    "\n",
    "retweetsD1 = [{'tweet': tweet, 'rts': rt, 'ids': idd} for tweet,rt,idd in zip(tweets,rts,ids)]\n",
    "\n",
    "\n",
    "\n",
    "day_list = []\n",
    "count = 0\n",
    "for tweet in items:\n",
    "    current_date = datetime.strptime(tweet['created_at'],'%Y-%m-%d %H:%M:%S+00:00')\n",
    "    # if (current_date.year == 2020) and (current_date.month == 11) and (current_date.day < 17):\n",
    "    date_time_str = str(current_date.day) +\"/\"+ str(current_date.month) +\"/\"+ str(current_date.year)\n",
    "    # print(date_time_str)\n",
    "    # day_list.append(str(current_date.day) +\"/\"+ str(current_date.month))\n",
    "    date_time_obj = datetime.strptime(date_time_str, '%d/%m/%Y')\n",
    "    # print(date_time_obj)\n",
    "    day_list.append(date_time_obj)\n",
    "\n",
    "day_dict = {}\n",
    "\n",
    "\n",
    "for day in day_list:\n",
    "    if day in day_dict:\n",
    "        day_dict[day] += 1\n",
    "    else:\n",
    "        day_dict[day] = 1\n",
    "\n",
    "\n",
    "DatasV1 = []\n",
    "DatasV2 = []\n",
    "\n",
    "# #going to break on cases that go from 23 to midnight or backwards\n",
    "# print('\\n#########   Printing hourly traffic   #########\\n')\n",
    "for key, value in sorted(iter(day_dict.items()), reverse=False, key=lambda k_v: (k_v[0],k_v[1])):\n",
    "    chave = str(key)\n",
    "    chave = re.sub(\" 00:00:00\",\"\", chave)\n",
    "    DatasV1.append(chave)\n",
    "    DatasV2.append(value)\n",
    "    # print('%s: %s' % (key, value))\n",
    "DatasD1 = dict(zip(DatasV1, DatasV2))\n",
    "\n",
    "# json.dump({report:[{'words':wordsD1},{'hashtags':hashtagD1},{'users':usersD1},{'retweets':retweetsD1},{'dates':DatasD1}]},pre_jsonReport, indent=4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3ce34-cbe2-4074-a2b8-70de5c78d2ef",
   "metadata": {},
   "source": [
    "#### 2.24 - Gera a visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22020df0-f311-421c-83a8-4efbcdd78b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "axd = plt.figure(figsize=(7,15)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    A\n",
    "    B\n",
    "    C\n",
    "    \"\"\",\n",
    "    gridspec_kw={\n",
    "        # 'width_ratios': [5, 5, 7],\n",
    "        # 'height_ratios': [5, 5, 7],\n",
    "        # 'right': 1.2,\n",
    "        # 'left': 1,\n",
    "        'hspace': 0.3\n",
    "        \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# usersV1.reverse()\n",
    "# usersV2.reverse()\n",
    "\n",
    "# hashtagV1.reverse()\n",
    "# hashtagV2.reverse()\n",
    "\n",
    "\n",
    "axd['A'].barh(usersV1, usersV2, color='green')\n",
    "\n",
    "for i, v in enumerate(usersV2):\n",
    "    axd['A'].text(v-450, i-.07, str(v), color='white',size=12)\n",
    "\n",
    "\n",
    "\n",
    "axd['B'].barh(hashtagV1, hashtagV2, color='purple')\n",
    "\n",
    "for i, v in enumerate(hashtagV2):\n",
    "    axd['B'].text(v-200, i-0.1, str(v), color='white',size=12)\n",
    "\n",
    "\n",
    "axd['A'].set_yticklabels(usersV1,fontsize=13)\n",
    "axd['B'].set_yticklabels(hashtagV1,fontsize=13)\n",
    "\n",
    "   \n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    # width = 280,\n",
    "    # height = 2800,\n",
    "    prefer_horizontal=1,\n",
    "    max_font_size=40,\n",
    "    min_font_size=10,\n",
    "    max_words=18,\n",
    "    background_color = 'white',\n",
    "    color_func=lambda *args, **kwargs: \"#D38B07\",\n",
    "    stopwords=stopwords).generate(str(vTwitter1))\n",
    "\n",
    "\n",
    "\n",
    "axd['A'].set_title('Usuários',fontsize=16)\n",
    "axd['B'].set_title('Hashtags',fontsize=16)\n",
    "axd['C'].set_title('Palavras',fontsize=16)\n",
    "\n",
    "axd['C'].axis('off')\n",
    "axd['C'].imshow(wordcloud)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# axd['A'].add_gridspec={'right': 100,'wspace': 30}\n",
    "plt.tight_layout()\n",
    "\n",
    "# axd['C'].imshow(wordcloud, interpolation = 'bilinear')\n",
    "\n",
    "\n",
    "plt.savefig(\"4 - Figura 10 - Usuários, hashtags e palavras mais utlizadas no Twitter.jpg\",bbox_inches = 'tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6272948-1bd5-40e1-a2d0-94c1f7308b3f",
   "metadata": {},
   "source": [
    "## 2.25 - Gera gráficos do Rio Grande do Sul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72594c0d-67c6-43c9-842e-741f272e1ac5",
   "metadata": {},
   "source": [
    "### 2.26 - Carrega base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d85dc-60c9-4e22-bc79-017fa79aef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_proposicoes = pd.read_csv(\"usuarios_proposicoes-2.csv\")\n",
    "tweets2020 = pd.read_csv(\"tweets2020.csv\")\n",
    "# usuarios_proposicoes.head(2)\n",
    "usuarios_proposicoes_rs = usuarios_proposicoes[(usuarios_proposicoes['ESTADO_ELEICAO']=='RS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65eb761-77a6-4bac-b0c6-c6dea83afaf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.27 - Temas mais recorrentes nas proposições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31c556-53e1-4ab3-9cc7-46b0889738ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "perfil = 'ESTADO_ELEICAO'\n",
    "\n",
    "filtro =usuarios_proposicoes[usuarios_proposicoes['ESTADO_ELEICAO'].isin(['RS'])]\n",
    "\n",
    "lang_responses = usuarios_proposicoes['TEMA']\n",
    "\n",
    "language_counter = Counter()\n",
    "    \n",
    "for response in lang_responses:\n",
    "    language_counter.update(response.split(','))\n",
    "        \n",
    "languages = []\n",
    "popularity = []\n",
    "    \n",
    "for item in language_counter.most_common(100):\n",
    "    languages.append(item[0])\n",
    "    popularity.append(item[1])\n",
    "    \n",
    "    \n",
    "\n",
    "# language_counter\n",
    "\n",
    "\n",
    "\n",
    "contagem_geral = dict(language_counter)\n",
    "df = pd.DataFrame.from_dict(contagem_geral, orient='index')\n",
    "# df.columns['TEMA','COUNT']\n",
    "           \n",
    "     \n",
    "           \n",
    "df.rename(columns = {0:'count'},inplace = True)\n",
    "\n",
    "df.index.name = 'TEMA'\n",
    "df['ESTADO_ELEICAO'] = 'GERAL'\n",
    "\n",
    "\n",
    "df.reset_index()\n",
    "df.columns\n",
    "# df\n",
    "temas = df[['ESTADO_ELEICAO', 'count']]\n",
    "temas = temas.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6765df4-2e93-401a-8959-f067a64742a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = temas.groupby([perfil],as_index=False).agg({\n",
    "    perfil: \"first\",\n",
    "    'count': 'sum'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "temasM_geral = pd.merge(temas, soma, how=\"left\", on=perfil)\n",
    "temasM_geral['proporcao'] = round(temasM_geral['count_x']/temasM_geral['count_y']*100,2)\n",
    "\n",
    "\n",
    "# rd = px.line_polar(temasM_geral, r=\"proporcao\", theta=\"TEMA\", color=perfil,line_close=True, width=wd, height=ht)\n",
    "\n",
    "# rd.update_layout(\n",
    "#     margin=dict(l=ll, r=rr, t=tt, b=bb),\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe84367-ce71-4835-b7ae-50bdaaf9e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temasM_geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13aec3-c8c6-496e-9f6f-b80da3befcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "perfil = 'ESTADO_ELEICAO' \n",
    "filtro =usuarios_proposicoes[usuarios_proposicoes['ESTADO_ELEICAO'].isin(['RS'])]\n",
    "\n",
    "\n",
    "\n",
    "filtro =usuarios_proposicoes[usuarios_proposicoes['ESTADO_ELEICAO'].isin(['RS'])]\n",
    "\n",
    "lang_responses = filtro['TEMA']\n",
    "\n",
    "language_counter = Counter()\n",
    "    \n",
    "for response in lang_responses:\n",
    "    language_counter.update(response.split(','))\n",
    "        \n",
    "languages = []\n",
    "popularity = []\n",
    "    \n",
    "for item in language_counter.most_common(100):\n",
    "    languages.append(item[0])\n",
    "    popularity.append(item[1])\n",
    "    \n",
    "    \n",
    "\n",
    "# language_counter\n",
    "\n",
    "\n",
    "\n",
    "contagem_geral = dict(language_counter)\n",
    "df = pd.DataFrame.from_dict(contagem_geral, orient='index')\n",
    "# df.columns['TEMA','COUNT']\n",
    "           \n",
    "     \n",
    "           \n",
    "df.rename(columns = {0:'count'},inplace = True)\n",
    "\n",
    "df.index.name = 'TEMA'\n",
    "df['ESTADO_ELEICAO'] = 'RS'\n",
    "\n",
    "\n",
    "df.reset_index()\n",
    "df.columns\n",
    "# df\n",
    "temas = df[['ESTADO_ELEICAO', 'count']]\n",
    "temas = temas.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331b813-cb4b-42bf-889e-0784aacbba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = temas.groupby([perfil],as_index=False).agg({\n",
    "    perfil: \"first\",\n",
    "    'count': 'sum'\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "temasM_rs = pd.merge(temas, soma, how=\"left\", on=perfil)\n",
    "temasM_rs['proporcao'] = round(temasM_rs['count_x']/temasM_rs['count_y']*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59ba1b-3370-4dc9-bc7d-e7bf71ad79e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temasM_rs.sort_values(by='count_x', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5dd04-b214-4de1-82af-47739ec30b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "temasM_geral = temasM_geral.nlargest(30, 'count_x')\n",
    "temasM_geral = temasM_geral.sort_values(by='TEMA')\n",
    "\n",
    "temasM_rs = temasM_rs.nlargest(30, 'count_x')\n",
    "temasM_rs = temasM_rs.sort_values(by='TEMA')\n",
    "\n",
    "TEMAS_C = pd.concat([temasM_geral, temasM_rs])\n",
    "TEMAS_C.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c8bdb-e9e8-43f6-8795-71a467fac4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1000\n",
    "ht = 800\n",
    "ll = 300\n",
    "rr = 250\n",
    "tt = 5\n",
    "bb = 5\n",
    "\n",
    "arq = \"novos-graficos/Gráfico x - Temas mais recorrentes nas proposições - Rio Grande do Sul.jpg\"\n",
    "\n",
    "rd = px.line_polar(TEMAS_C, r=\"proporcao\", theta=\"TEMA\", color=perfil,line_close=True, width=wd, height=ht)\n",
    "\n",
    "rd.update_layout(\n",
    "    margin=dict(l=ll, r=rr, t=tt, b=bb),\n",
    "\n",
    ")\n",
    "\n",
    "# rd.show()\n",
    "\n",
    "rd.write_image(arq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a950ec5-24a2-49ce-a93b-5553be5fe99c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.28 - Publicações mais compartilhadas no Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df1eef-e4ae-4454-8e12-b2a17a0ae2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "# perfil = 'ST_REELEICAO'\n",
    "def topRTs2(perfil):\n",
    "    unik = list(filtro[perfil].unique())\n",
    "    # len(unik)\n",
    "    # listalista = [[] for i in range(len(unik))]\n",
    "    listas = []\n",
    "    # lista\n",
    "\n",
    "\n",
    "    for idx, k in enumerate(unik):\n",
    "        # listalista[idx].append(filtro[filtro[perfil]==k]['SCREEN_NAME'].astype(\"str\").values.tolist())\n",
    "        listas.append(filtro[filtro[perfil]==k]['SCREEN_NAME'].astype(\"str\").values.tolist())\n",
    "\n",
    "    # len(lista)\n",
    "    # lista[1]\n",
    "\n",
    "\n",
    "    for idx,s in enumerate(listas):\n",
    "        print(unik[idx])\n",
    "        tweets2020F = tweets2020[tweets2020['screen_name'].isin(listas[idx])]        \n",
    "        # tweets2020F\n",
    "\n",
    "        # \n",
    "        # tweets2020.head(2)\n",
    "        topTweets = tweets2020F.nlargest(5,'retweet_count')\n",
    "        # tweetsTop10\n",
    "        topIds = topTweets['id'].astype(\"str\").values.tolist()\n",
    "\n",
    "        string = \"https://twitter.com/OReillyMedia/status/\"\n",
    "\n",
    "        topIds = [string + s for s in topIds]\n",
    "        # topIds\n",
    "\n",
    "        class Tweet(object):\n",
    "            def __init__(self, s, embed_str=False):\n",
    "                try:\n",
    "                    if not embed_str:\n",
    "                        # Use Twitter's oEmbed API\n",
    "                        # https://dev.twitter.com/web/embedded-tweets\n",
    "                        api = 'https://publish.twitter.com/oembed?url={}'.format(s)\n",
    "                        response = requests.get(api)\n",
    "                        self.text = response.json()[\"html\"]\n",
    "                        display(HTML(self.text))\n",
    "                    else:\n",
    "                        self.text = s\n",
    "                except Exception:\n",
    "                    pass\n",
    "                        \n",
    "\n",
    "            def _repr_html_(self):\n",
    "                try:\n",
    "                    return self.text\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # Tweet(\"https://twitter.com/OReillyMedia/status/1253710046405500928\")\n",
    "\n",
    "        for x in topIds:\n",
    "            Tweet(x)\n",
    "        # vTweets(topIds)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa702f5e-62b8-4831-aa26-28657a5ed588",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfil = 'ESTADO_ELEICAO' \n",
    "filtro =usuarios_proposicoes[usuarios_proposicoes['ESTADO_ELEICAO'].isin(['RS'])]\n",
    "topRTs2(perfil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9ad42-b410-41b7-a752-6dcc45bb7a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b44d6fa-9a56-4742-9d7b-bf2012a6ce9d",
   "metadata": {},
   "source": [
    "<h3>2.29 - Usuários e hashtags e palavras mais frequentes no Twitter </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e296db6-a36c-4e9d-a319-63c15972b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_proposicoes_rs = usuarios_proposicoes[(usuarios_proposicoes['ESTADO_ELEICAO']=='RS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a9d32-772e-4aab-9e93-4574799733ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDeputados = pd.read_csv(\"db-listaDeputados.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253b09d-6110-48e0-b9a4-c4c9adbab2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsTwitter = usuarios_proposicoes_rs['TWEET_KEYWORDS'].astype(\"str\").values.tolist()\n",
    "\n",
    "vTwitter1 = []\n",
    "\n",
    "f = open(\"stopwords.txt\", 'r', encoding='utf-8')\n",
    "stopwords = [name.rstrip().lower() for name in f]\n",
    "\n",
    "for tweet in keywordsTwitter:\n",
    "    tweet = re.sub(r'\\n',' ',unidecode(tweet))\n",
    "    tweet = tweet.replace(\"  \",\" \")\n",
    "    # tweet = tweet.replace(\"paraben\",\"parabens\")\n",
    "    tweet = \" \".join([x for x in tweet.split(' ') if x.lower() not in stopwords])\n",
    "    vTwitter1.append(tweet) \n",
    "# vFrases  \n",
    "\n",
    "# tweets2020['TWEET_KEYWORDS'] = vFrases\n",
    "# len(vTwitter)\n",
    "# len(vTwitter1)\n",
    "# vTwitter[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f894f-c64e-480f-a3e8-a4b567edb89f",
   "metadata": {},
   "source": [
    "#### 2.30 - Extrai as informações dos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192db928-2d80-4a21-8c75-ee8d5836dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDeputados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47821682-50a1-4452-b9f4-3eaebcd07331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tweets2020)\n",
    "\n",
    "tweets2020_info = tweets2020.merge(listaDeputados, left_on='screen_name', right_on='PERFIL_TWITTER')\n",
    "# len(tweets2020_info)\n",
    "# tweets2020_rs = \n",
    "# tweets2020_info\n",
    "\n",
    "tweets2020_info_rs = tweets2020_info[(tweets2020_info['ESTADO_ELEICAO']=='RS')]\n",
    "len(tweets2020_info_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36966f5a-2e2f-47d5-abdc-12bb078cb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_repetition = 1\n",
    "hashtags_repetition = 1\n",
    "users_repetition = 1\n",
    "\n",
    "#variables for how many words, hashtags, users to display\n",
    "word_limit = 10\n",
    "hashtag_limit = 10\n",
    "user_limit = 10\n",
    "\n",
    "#file path for stopwords and json exports\n",
    "stopwords_file_path = 'stopwords.txt'\n",
    "# json_export_file_path = '1-total.json'\n",
    "\n",
    "with open(stopwords_file_path, encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "items = tweets2020_info_rs.to_dict('records')\n",
    "# items[0]\n",
    "\n",
    "#taken from https://stackoverflow.com/a/49146722\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                        \"\\U00002702-\\U000027B0\"\n",
    "                        \"\\U000024C2-\\U0001F251\"\n",
    "                        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "#taken from https://gist.github.com/glenbot/4684356\n",
    "def sanitize_3(user_input, stop_words):\n",
    "    \"\"\"Sanitize using standard lists\"\"\"\n",
    "    new_list = []\n",
    "    for w in user_input:\n",
    "        if w not in stop_words:\n",
    "            new_list.append(w)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "#remove accents, emoji, convert to all lowercase\n",
    "for idx, item in enumerate(items):\n",
    "    items[idx]['text'] = remove_emoji(items[idx]['text'])\n",
    "    items[idx]['text'] = unidecode(items[idx]['text'])\n",
    "    items[idx]['text'] = items[idx]['text'].lower()\n",
    "    #print items[idx]['text']\n",
    "\n",
    "\n",
    "#removing stopwords\n",
    "#convert every tweet into a list of words\n",
    "#call sanitize_3 for every list of words\n",
    "current_string = ''\n",
    "placeholder_list = [None] * len(items)\n",
    "master_word_list = []\n",
    "master_hashtag_list = []\n",
    "master_user_list = []\n",
    "\n",
    "for idx, item in enumerate(items):\n",
    "    #word_list = re.sub(\"[^\\w]\", \" \", items[idx]['text']).split()\n",
    "    word_list = re.sub(r'[.!,;:?]', ' ', items[idx]['text']).split()\n",
    "    word_list = sanitize_3(word_list, stopwords)\n",
    "    for idx2, word in enumerate(word_list):\n",
    "        if word_list[idx2][:1] == '#':\n",
    "            current_string += ' ' + word_list[idx2]\n",
    "            master_hashtag_list.append(word_list[idx2])\n",
    "        elif word_list[idx2][:1] == '@':\n",
    "            current_string += ' ' + word_list[idx2]\n",
    "            master_user_list.append(word_list[idx2])\n",
    "        elif word_list[idx2][:3] == '//t':              #dirty workaround\n",
    "            pass\n",
    "        elif 'co/' not in word_list[idx2]:\n",
    "            current_string += ' ' + word_list[idx2]\n",
    "            master_word_list.append(word_list[idx2])\n",
    "    placeholder_list[idx] = current_string\n",
    "    current_string = ''\n",
    "\n",
    "\n",
    "#release memory immediately\n",
    "del placeholder_list[:]\n",
    "\n",
    "#rank words\n",
    "#adapted from https://github.com/kevinschaul/Word-Rank/blob/master/wordRank.py\n",
    "l = {}\n",
    "hashtag_dict = {}\n",
    "user_dict = {}\n",
    "\n",
    "for word in master_word_list:\n",
    "    # if word is in dictionary, increment the value\n",
    "    # otherwise add the word to dictionary with value 1\n",
    "    if word in l:\n",
    "        l[word] += 1\n",
    "    else:\n",
    "        l[word] = 1\n",
    "\n",
    "for hashtag in master_hashtag_list:\n",
    "    if hashtag in hashtag_dict:\n",
    "        hashtag_dict[hashtag] += 1\n",
    "    else:\n",
    "        hashtag_dict[hashtag] = 1\n",
    "\n",
    "for user in master_user_list:\n",
    "    if user in user_dict:\n",
    "        user_dict[user] += 1\n",
    "    else:\n",
    "        user_dict[user] = 1\n",
    "\n",
    "\n",
    "wordsV1 = []\n",
    "wordsV2 = []\n",
    "\n",
    "# this prints the dict out sorted by value in descending order\n",
    "count = 0\n",
    "# print('\\n#########   Printing ranking of words   #########\\n')\n",
    "for key, value in sorted(iter(l.items()), reverse=True, key=lambda k_v3: (k_v3[1],k_v3[0])):\n",
    "    if count < word_limit:\n",
    "        # print('%s: %s' % (key, value))\n",
    "        wordsV1.append(key)\n",
    "        wordsV2.append(value)\n",
    "    count+=1\n",
    "\n",
    "wordsD1 = dict(zip(wordsV1, wordsV2))\n",
    "# print(wordsD1)\n",
    "\n",
    "hashtagV1 = []\n",
    "hashtagV2 = []\n",
    "\n",
    "count = 0\n",
    "# print('\\n#########   Printing ranking of hashtags   #########\\n')\n",
    "for key, value in sorted(iter(hashtag_dict.items()), reverse=True, key=lambda k_v4: (k_v4[1],k_v4[0])):\n",
    "    if count < hashtag_limit:\n",
    "        # print('%s: %s' % (key, value))\n",
    "        hashtagV1.append(key)\n",
    "        hashtagV2.append(value)\n",
    "        \n",
    "    count +=1\n",
    "\n",
    "hashtagD1 = dict(zip(hashtagV1, hashtagV2))\n",
    "\n",
    "# print(hashtagD1)\n",
    "\n",
    "# plt.rcdefaults()\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# y_pos = np.arange(len(hashtagV1))\n",
    "# error = np.random.rand(len(hashtagV1))\n",
    "\n",
    "# ax.barh(y_pos, hashtagV2, xerr=error, align='center')\n",
    "# ax.set_yticks(y_pos)\n",
    "# ax.set_yticklabels(hashtagV1)\n",
    "# ax.invert_yaxis()  # labels read top-to-bottom\n",
    "# ax.set_xlabel('Frequência')\n",
    "# ax.set_title('Hashtags mais utilizadas')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "usersV1 = []\n",
    "usersV2 = []\n",
    "\n",
    "count = 0\n",
    "# print('\\n#########   Printing ranking of most mentioned users   #########\\n')\n",
    "for key, value in sorted(iter(user_dict.items()), reverse=True, key=lambda k_v5: (k_v5[1],k_v5[0])):\n",
    "    if count < user_limit:\n",
    "        # print('%s: %s' % (key, value))\n",
    "        usersV1.append(key)\n",
    "        usersV2.append(value)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "usersD1 = dict(zip(usersV1, usersV2))\n",
    "# print(usersD1)\n",
    "\n",
    "most_retweeted_list = []\n",
    "list_is_full = False\n",
    "\n",
    "for tweet in items:\n",
    "    if 'rt @' in tweet['text']:\n",
    "        pass\n",
    "    elif tweet['retweet_count'] > 10:\n",
    "        most_retweeted_list.append(tweet)\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "tweets =[]\n",
    "rts = []\n",
    "ids = []\n",
    "\n",
    "# print('\\n#########   Printing most retweeted tweets   #########\\n')\n",
    "for tweet in sorted(most_retweeted_list, key = lambda x: x['retweet_count'], reverse=True):\n",
    "    current_date = datetime.strptime(tweet['created_at'],'%Y-%m-%d %H:%M:%S+00:00')\n",
    "    # if (current_date.year == 2020) and (current_date.month == 11) and (current_date.day < 17):\n",
    "    tweets.append(tweet['screen_name'] +\" - \"+ tweet['text'])\n",
    "    rts.append(tweet['retweet_count'])\n",
    "    ids.append(tweet['id'])\n",
    "    if count == 20:\n",
    "        break\n",
    "    count+=1\n",
    "\n",
    "# rtKeys1 = ['tweet','rts','ids']\n",
    "# rtKeys2 =  rtKeys1 *len(ids)\n",
    "# print(rtKeys2)\n",
    "\n",
    "retweetsD1 = [{'tweet': tweet, 'rts': rt, 'ids': idd} for tweet,rt,idd in zip(tweets,rts,ids)]\n",
    "\n",
    "\n",
    "\n",
    "day_list = []\n",
    "count = 0\n",
    "for tweet in items:\n",
    "    current_date = datetime.strptime(tweet['created_at'],'%Y-%m-%d %H:%M:%S+00:00')\n",
    "    # if (current_date.year == 2020) and (current_date.month == 11) and (current_date.day < 17):\n",
    "    date_time_str = str(current_date.day) +\"/\"+ str(current_date.month) +\"/\"+ str(current_date.year)\n",
    "    # print(date_time_str)\n",
    "    # day_list.append(str(current_date.day) +\"/\"+ str(current_date.month))\n",
    "    date_time_obj = datetime.strptime(date_time_str, '%d/%m/%Y')\n",
    "    # print(date_time_obj)\n",
    "    day_list.append(date_time_obj)\n",
    "\n",
    "day_dict = {}\n",
    "\n",
    "\n",
    "for day in day_list:\n",
    "    if day in day_dict:\n",
    "        day_dict[day] += 1\n",
    "    else:\n",
    "        day_dict[day] = 1\n",
    "\n",
    "\n",
    "DatasV1 = []\n",
    "DatasV2 = []\n",
    "\n",
    "# #going to break on cases that go from 23 to midnight or backwards\n",
    "# print('\\n#########   Printing hourly traffic   #########\\n')\n",
    "for key, value in sorted(iter(day_dict.items()), reverse=False, key=lambda k_v: (k_v[0],k_v[1])):\n",
    "    chave = str(key)\n",
    "    chave = re.sub(\" 00:00:00\",\"\", chave)\n",
    "    DatasV1.append(chave)\n",
    "    DatasV2.append(value)\n",
    "    # print('%s: %s' % (key, value))\n",
    "DatasD1 = dict(zip(DatasV1, DatasV2))\n",
    "\n",
    "# json.dump({report:[{'words':wordsD1},{'hashtags':hashtagD1},{'users':usersD1},{'retweets':retweetsD1},{'dates':DatasD1}]},pre_jsonReport, indent=4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e45fd-21fa-4fb3-9d59-8514ed353a12",
   "metadata": {},
   "source": [
    "#### 2.31 - Gera a visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47c152-2dc4-4a66-9415-53dc9f510386",
   "metadata": {},
   "outputs": [],
   "source": [
    "axd = plt.figure(figsize=(6,10)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    A\n",
    "    B\n",
    "    \"\"\",\n",
    "    gridspec_kw={\n",
    "        # 'width_ratios': [5, 5, 7],\n",
    "        # 'height_ratios': [5, 5, 7],\n",
    "        # 'right': 1.2,\n",
    "        # 'left': 1,\n",
    "        # 'hspace': 0.3\n",
    "        \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# usersV1.reverse()\n",
    "# usersV2.reverse()\n",
    "\n",
    "# hashtagV1.reverse()\n",
    "# hashtagV2.reverse()\n",
    "\n",
    "\n",
    "axd['A'].barh(usersV1, usersV2, color='green')\n",
    "\n",
    "for i, v in enumerate(usersV2):\n",
    "    axd['A'].text(v-30, i-.07, str(v), color='white',size=12)\n",
    "\n",
    "\n",
    "\n",
    "axd['B'].barh(hashtagV1, hashtagV2, color='purple')\n",
    "\n",
    "for i, v in enumerate(hashtagV2):\n",
    "    axd['B'].text(v-28, i-0.1, str(v), color='white',size=12)\n",
    "\n",
    "\n",
    "axd['A'].set_yticklabels(usersV1,fontsize=13)\n",
    "axd['B'].set_yticklabels(hashtagV1,fontsize=13)\n",
    "\n",
    "   \n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "axd['A'].set_title('Usuários',fontsize=16)\n",
    "axd['B'].set_title('Hashtags',fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# axd['A'].add_gridspec={'right': 100,'wspace': 30}\n",
    "# plt.tight_layout()\n",
    "\n",
    "# axd['C'].imshow(wordcloud, interpolation = 'bilinear')\n",
    "\n",
    "\n",
    "plt.savefig(\"novos-graficos/Figura x - Usuários, hashtags e palavras mais frequentes no Twitter - Rio Grande do Sul.jpg\",bbox_inches = 'tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d35e1-da99-447c-b63e-c5b16b2bc566",
   "metadata": {},
   "source": [
    "### 2.32 - Palavras mais utilizadas nas proposições e tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec1dba-108c-40a6-a197-69301dbd1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagclouds(perfil,ws,hs,arq):\n",
    "    unik = list(usuarios_proposicoes[perfil].unique())\n",
    "    tags = [\"PLS_KEYWORDS\", \"TWEET_KEYWORDS\", \"INTERSECAO\"]\n",
    "\n",
    "    nomes = ['Projetos de Lei', 'Tweets', 'Interseção']\n",
    "\n",
    "    axs1 = []\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    # gs0 = matplotlib.gridspec.GridSpec(len(unik),len(tags), figure=fig)\n",
    "    gs0 = matplotlib.gridspec.GridSpec(len(unik),len(tags), figure=fig,wspace=ws,hspace=hs)\n",
    "\n",
    "\n",
    "    for i1,t in enumerate(unik):\n",
    "        for i2,k in enumerate(tags):\n",
    "            axs1.append(fig.add_subplot(gs0[i1,i2]))\n",
    "\n",
    "\n",
    "    cores = ['#D38B07', '#3399FF','#ABAB5B']\n",
    "    mxCores = [cores for k in unik]\n",
    "\n",
    "    matrix = [tags for k in unik]\n",
    "    indMatrix1 = [[i for i in range(len(tags))] for value in matrix]\n",
    "    contagem = [i for i in range(len(tags)*len(unik))]\n",
    "    indMatrix2 = [contagem[x:x+3] for x in range(0, len(contagem), 3)]\n",
    "\n",
    "\n",
    "\n",
    "    f = open(\"stopwords.txt\", 'r', encoding='utf-8')\n",
    "    stopwords = [name.rstrip().lower() for name in f]\n",
    "\n",
    "\n",
    "\n",
    "    # for idx1, t in enumerate(tags):\n",
    "    for idx1, k in enumerate(unik):\n",
    "\n",
    "        for idx2, t in enumerate(tags):\n",
    "        # for idx2, k in enumerate(unik):\n",
    "            wordcloud = WordCloud(\n",
    "                # width = 50,\n",
    "                # height = 50,\n",
    "                prefer_horizontal=1,\n",
    "                max_font_size=40,\n",
    "                min_font_size=10,\n",
    "                max_words=10,\n",
    "                background_color = 'white',\n",
    "                color_func=lambda *args, **kwargs: mxCores[idx1][idx2],\n",
    "                # color_func=lambda *args, **kwargs: cores[idx2],\n",
    "                stopwords=stopwords).generate(str(usuarios_proposicoes[usuarios_proposicoes[perfil]==k][t]))\n",
    "\n",
    "\n",
    "            logro = []\n",
    "            axs1[indMatrix2[idx1][idx2]].set_yticklabels(logro)\n",
    "            axs1[indMatrix2[idx1][0]].set_ylabel(unik[idx1],fontsize=17)\n",
    "            axs1[idx2].set_title(nomes[idx2],fontsize=17)\n",
    "\n",
    "            axs1[indMatrix2[idx1][idx2]].tick_params(\n",
    "            axis='both',          \n",
    "            which='both',     \n",
    "            bottom=False,      \n",
    "            top=False,         \n",
    "            # left=False,        \n",
    "            # labelleft=False, \n",
    "            labelbottom=False) \n",
    "\n",
    "\n",
    "            axs1[indMatrix2[idx1][idx2]].imshow(wordcloud, interpolation = 'bilinear')\n",
    "            # axs[idx].plot([-.1, 1.2], [0, 0], color='black', lw=1, transform=axs[idx].transAxes, clip_on=False)\n",
    "\n",
    "            # axd['A'].add_gridspec={'right': 100,'wspace': 30}\n",
    "            # plt.tight_layout()\n",
    "\n",
    "        plt.savefig(arq,bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87514c18-df34-4d8f-931f-c83a2eeb9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_proposicoes['GERAL'] = 'GERAL'\n",
    "\n",
    "perfil = 'GERAL'\n",
    "arq = \"novos-graficos/Figura x - Nuvens de palavras sobre proposições e tweets - Geral.jpg\"\n",
    "tagclouds(perfil,0.1,-0.73,arq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8b251-9c1f-456e-ac35-a497fa8c809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagclouds2(perfil,ws,hs,arq):\n",
    "    unik = list(filtro[perfil].unique())\n",
    "    tags = [\"PLS_KEYWORDS\", \"TWEET_KEYWORDS\", \"INTERSECAO\"]\n",
    "\n",
    "    nomes = ['Projetos de Lei', 'Tweets', 'Interseção']\n",
    "\n",
    "    axs1 = []\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    # gs0 = matplotlib.gridspec.GridSpec(len(unik),len(tags), figure=fig)\n",
    "    gs0 = matplotlib.gridspec.GridSpec(len(unik),len(tags), figure=fig,wspace=ws,hspace=hs)\n",
    "\n",
    "\n",
    "    for i1,t in enumerate(unik):\n",
    "        for i2,k in enumerate(tags):\n",
    "            axs1.append(fig.add_subplot(gs0[i1,i2]))\n",
    "\n",
    "\n",
    "    cores = ['#D38B07', '#3399FF','#ABAB5B']\n",
    "    mxCores = [cores for k in unik]\n",
    "\n",
    "    matrix = [tags for k in unik]\n",
    "    indMatrix1 = [[i for i in range(len(tags))] for value in matrix]\n",
    "    contagem = [i for i in range(len(tags)*len(unik))]\n",
    "    indMatrix2 = [contagem[x:x+3] for x in range(0, len(contagem), 3)]\n",
    "\n",
    "\n",
    "\n",
    "    f = open(\"stopwords.txt\", 'r', encoding='utf-8')\n",
    "    stopwords = [name.rstrip().lower() for name in f]\n",
    "\n",
    "\n",
    "\n",
    "    # for idx1, t in enumerate(tags):\n",
    "    for idx1, k in enumerate(unik):\n",
    "\n",
    "        for idx2, t in enumerate(tags):\n",
    "        # for idx2, k in enumerate(unik):\n",
    "            wordcloud = WordCloud(\n",
    "                # width = 50,\n",
    "                # height = 50,\n",
    "                prefer_horizontal=1,\n",
    "                max_font_size=40,\n",
    "                min_font_size=10,\n",
    "                max_words=10,\n",
    "                background_color = 'white',\n",
    "                color_func=lambda *args, **kwargs: mxCores[idx1][idx2],\n",
    "                # color_func=lambda *args, **kwargs: cores[idx2],\n",
    "                stopwords=stopwords).generate(str(filtro[filtro[perfil]==k][t]))\n",
    "\n",
    "\n",
    "            logro = []\n",
    "            axs1[indMatrix2[idx1][idx2]].set_yticklabels(logro)\n",
    "            axs1[indMatrix2[idx1][0]].set_ylabel(unik[idx1],fontsize=17)\n",
    "            axs1[idx2].set_title(nomes[idx2],fontsize=17)\n",
    "\n",
    "            axs1[indMatrix2[idx1][idx2]].tick_params(\n",
    "            axis='both',          \n",
    "            which='both',     \n",
    "            bottom=False,      \n",
    "            top=False,         \n",
    "            # left=False,        \n",
    "            # labelleft=False, \n",
    "            labelbottom=False) \n",
    "\n",
    "\n",
    "            axs1[indMatrix2[idx1][idx2]].imshow(wordcloud, interpolation = 'bilinear')\n",
    "            # axs[idx].plot([-.1, 1.2], [0, 0], color='black', lw=1, transform=axs[idx].transAxes, clip_on=False)\n",
    "\n",
    "            # axd['A'].add_gridspec={'right': 100,'wspace': 30}\n",
    "            # plt.tight_layout()\n",
    "\n",
    "        plt.savefig(arq,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ddd93d-3e03-4f2e-8873-d6c06957bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arq = \"novos-graficos/Figura x - Nuvens de palavras sobre proposições e tweets - Rio Grande do Sul.jpg\"\n",
    "filtro =usuarios_proposicoes[usuarios_proposicoes['ESTADO_ELEICAO'].isin(['RS'])]\n",
    "perfil = 'ESTADO_ELEICAO' \n",
    "\n",
    "tagclouds2(perfil,0.1,-0.5,arq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73832d6-6d0d-4fa7-bd42-5390d5c0f001",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 - Formação de redes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd759a2e-78b3-4771-8e22-a3b6fa38963c",
   "metadata": {},
   "source": [
    "### 3.1 - Carrega bases de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c3c0b-b399-4101-824e-b122f463eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDeputados = pd.read_csv(\"db-listaDeputados.csv\")\n",
    "\n",
    "usuarios_proposicoes = pd.read_csv(\"usuarios_proposicoes-2.csv\")\n",
    "tweets2020 = pd.read_csv(\"tweets2020.csv\")\n",
    "# usuarios_proposicoes.head(2)\n",
    "usuarios_proposicoes_rs = usuarios_proposicoes[(usuarios_proposicoes['ESTADO_ELEICAO']=='RS')]\n",
    "\n",
    "votacoes = pd.read_csv(\"db-votacoes.csv\")\n",
    "\n",
    "\n",
    "usuarios_proposicoes_rs.to_csv(\"db-usuarios-rs.csv\", index=False)\n",
    "\n",
    "# len(tweets2020)\n",
    "proposicoes = pd.read_csv(\"db-proposicoes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ee74f-0fa5-4861-bf6e-acc6a389e349",
   "metadata": {},
   "source": [
    "### 3.2 - Junta os tweets com as informações demográficos dos seus autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a1ca17-98f6-4196-9a67-3b34dc86bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets2020_info = tweets2020.merge(listaDeputados, left_on='screen_name', right_on='PERFIL_TWITTER')\n",
    "tweets2020_info_rs = tweets2020_info[(tweets2020_info['ESTADO_ELEICAO']=='RS')]\n",
    "# len(tweets2020_info_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e00c5e-e788-4e7c-bcc7-fea7f9cb2c8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.3 - Proposições com maior percentual de aprovação e rejeição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e607ac-4960-48d5-a079-6cd25d71ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "votacoes[\"TITULO_PROPOSICAO\"] = votacoes[\"TITULO_PROPOSICAO\"].str.replace(\"\\((.*?)\\)\",\"\")\n",
    "\n",
    "votacoes[\"TITULO_PROPOSICAO\"] = votacoes[\"TITULO_PROPOSICAO\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f7ecc-bdc6-4cf3-b25c-5c2649c1aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "votacoes_c = votacoes[[\"TITULO_PROPOSICAO\",\"VOTOS_SIM\"]]\n",
    "votacoes_c = votacoes_c.drop_duplicates(subset='TITULO_PROPOSICAO')\n",
    "\n",
    "votacoes_c10 = votacoes_c.nlargest(5,'VOTOS_SIM').sort_values(by='VOTOS_SIM', ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "votacoes_c10['percentual'] = votacoes_c10.apply(lambda row: round(row.VOTOS_SIM/513*100,2), axis=1)\n",
    "\n",
    "votacoes_c10 = votacoes_c10.set_index('TITULO_PROPOSICAO')\n",
    "\n",
    "votacoes_c10['rotulos'] = votacoes_c10.apply(lambda row: str(int(row.VOTOS_SIM)) +\" (\"+ str(row.percentual)+\"%) \" , axis=1)\n",
    "\n",
    "votacoes_s10 = votacoes_c10['percentual']\n",
    "# type(votacoes_c10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9876fc7-7ac2-420f-b129-51849739b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "votacoes_b = votacoes[[\"TITULO_PROPOSICAO\",\"VOTOS_NAO\"]]\n",
    "# votacoes_b = votacoes_b.drop_duplicates(subset='TITULO_PROPOSICAO')\n",
    "\n",
    "votacoes_b10 = votacoes_b.nlargest(5,'VOTOS_NAO').sort_values(by='VOTOS_NAO', ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "votacoes_b10['percentual'] = votacoes_b10.apply(lambda row: round(row.VOTOS_NAO/513*100,2), axis=1)\n",
    "\n",
    "votacoes_b10 = votacoes_b10.set_index('TITULO_PROPOSICAO')\n",
    "\n",
    "votacoes_b10['rotulos'] = votacoes_b10.apply(lambda row: str(int(row.VOTOS_NAO)) +\" (\"+ str(row.percentual)+\"%) \" , axis=1)\n",
    "\n",
    "votacoes_n10 = votacoes_b10['percentual']\n",
    "# type(votacoes_b10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be770688-0914-400e-b3b3-2dd96e9d3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "axd = plt.figure(figsize=(8,10)).subplot_mosaic(\n",
    "    \"\"\"\n",
    "    A\n",
    "    B\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "top10 = votacoes_s10.plot(kind='barh', \n",
    "                        color='green', \n",
    "                        width=0.8,ax=axd['A'])\n",
    "\n",
    "\n",
    "indices1 = list(votacoes_c10['rotulos'])\n",
    "\n",
    "for i, v in enumerate(list(votacoes_s10)):\n",
    "    top10.text(v-18, i, indices1[i], color='white',weight='heavy')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "bottom10 = votacoes_n10.plot(kind='barh', \n",
    "                        color='#BC0D0D', \n",
    "                        width=0.8,ax=axd['B'])\n",
    "\n",
    "indices2 = list(votacoes_b10['rotulos'])\n",
    "\n",
    "for i, v in enumerate(list(votacoes_n10)):\n",
    "    bottom10.text(v-18, i, indices2[i], color='white',weight='heavy')\n",
    "    \n",
    "    \n",
    "top10.set_ylabel('')    \n",
    "top10.set_xlabel('')\n",
    "\n",
    "bottom10.set_ylabel('')    \n",
    "bottom10.set_xlabel('')\n",
    "\n",
    "bottom10.grid(color='b', linestyle='-', linewidth=.1)   \n",
    "top10.grid(color='b', linestyle='-', linewidth=.1)   \n",
    "\n",
    "plt.tight_layout()\n",
    "# axd\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(\"novos-graficos/Figura x - Índices de consistência temática por estado.jpg\",bbox_inches = 'tight')\n",
    "# plt.clf()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\"novos-graficos/Figura x - Proposições com maiores percentuais de aprovação e rejeição.jpg\",bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50533d4d-0ab8-4fe1-85cf-e08e76d8fbff",
   "metadata": {},
   "source": [
    "## 3.4 - Rede de coautoria de proposições parlamentares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16a1cd-dc3a-4c3a-848b-60be053dc2cf",
   "metadata": {},
   "source": [
    "### 3.5 - Criação do Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493c6f8-d538-4683-bfde-b43ecc1318cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "arq_grafo = \"db-proposicoes.csv\"\n",
    "arq_semantico = \"grafo-coautoria.csv\"\n",
    "df_col3 = pd.read_csv(arq_grafo)\n",
    "# writer.writerow(['TITULO_FRENTE','DEPUTADOS_INTEGRANTES'])\n",
    "# writer = csv.writer(fileOut)\n",
    "# reader = csv.reader(fileIn, delimiter=',')   \n",
    "with open(arq_grafo, encoding=\"utf-8\") as f:\n",
    "    vTweets = [row[\"NOME_AUTOR\"] for row in DictReader(f)]\n",
    "\n",
    "col1 = []\n",
    "col2 = []\n",
    "vcol3 = []\n",
    "\n",
    "for tweet in vTweets:\n",
    "    # print(tweet)\n",
    "    vPalavras = tweet.split(',')\n",
    "    nPalavras = len(vPalavras)\n",
    "\n",
    "    if nPalavras > 2:\n",
    "        nLinhas = 0\n",
    "        vNumeros = []\n",
    "        for i in range(nPalavras):\n",
    "            b = nPalavras-(i+1)\n",
    "            if b>0:\n",
    "                vNumeros.append(b)\n",
    "            nLinhas = nLinhas + b\n",
    "        vcol3.append(nLinhas)\n",
    "\n",
    "        nNumeros= len(vNumeros)\n",
    "        invNumeros = vNumeros[::-1]\n",
    "        \n",
    "        c1 = []\n",
    "        for i in range(nNumeros):\n",
    "            for j in range(vNumeros[i]):\n",
    "                c1.append(vPalavras[i])  \n",
    "        col1.extend(c1)\n",
    "\n",
    " \n",
    "        ordemC2 = []\n",
    "        for i in range(nNumeros):\n",
    "            for j in invNumeros:\n",
    "                ordemC2.append(j)\n",
    "            invNumeros.pop(0)\n",
    "\n",
    "        Mposicao = []\n",
    "        posicaoC2 = []\n",
    "        for i in range(int(nLinhas/nPalavras)):\n",
    "            for j in range(nPalavras):\n",
    "                posicaoC2.append(vPalavras[j])\n",
    "                Mposicao.append(j)\n",
    "\n",
    "        c2 =[]\n",
    "        c2[:] = [posicaoC2[i] for i in ordemC2]\n",
    "        col2.extend(c2)\n",
    "\n",
    "\n",
    "\n",
    "scol3 = df_col3[['TITULO_PROPOSICAO','TEMA', 'PALAVRAS_CHAVE','TIPO_AUTOR']].values.tolist()\n",
    "\n",
    "col3 = [c for c, i in zip(scol3, vcol3) for _ in range(i)]\n",
    "\n",
    "# print(len(col3))\n",
    "# print(len(col3))\n",
    "matriz = np.c_[col1,col2,col3]\n",
    "df = pd.DataFrame(columns=[\"SOURCE\",\"TARGET\",'TITULO_PROPOSICAO','TEMA', 'PALAVRAS_CHAVE','TIPO_AUTOR'], data=matriz)\n",
    "df['SOURCE'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['SOURCE'], inplace=True)\n",
    "df['TARGET'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['TARGET'], inplace=True)\n",
    "\n",
    "df.to_csv(arq_semantico, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60e434-427c-43d3-811a-e9a5547d53ce",
   "metadata": {},
   "source": [
    "### 3.6 - Filtro do Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e2d2d-6580-4085-86a7-cc2fed58d891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coautoria_r = pd.read_csv(\"grafo-coautoria.csv\")\n",
    "# len(proposicoes)\n",
    "\n",
    "# len(coautoria_r)\n",
    "coautoria_f = coautoria_r[(coautoria_r['TIPO_AUTOR']=='Deputado')]\n",
    "# len(coautoria_f)\n",
    "\n",
    "coautoria_info = coautoria_f.merge(usuarios_proposicoes, left_on='SOURCE', right_on='NOME_AUTOR',how='inner')\n",
    "\n",
    "# coautoria_info.shape[0]\n",
    "# list(coautoria_info.columns)\n",
    "\n",
    "keepcol = ['SOURCE','TARGET','TITULO_PROPOSICAO_x','TEMA_x','PALAVRAS_CHAVE','TIPO_AUTOR','NOME_AUTOR','N_PLS','GENERO','COR_RACA','ESTADO_CIVIL','ESCOLARIDADE','OCUPACAO_ANTERIOR','FAIXA_ETARIA','PARTIDO_ATUAL','IDEOLOGIA_PARTIDO_ATUAL','MILIONARIO','ESTADO_ELEICAO','REGIAO_ELEICAO','ST_REELEICAO','AGRUPAMENTO_IDADE','AGRUPAMENTO_BENS','AGRUPAMENTO_VOTOS','AGRUPAMENTO_SEGUIDORES','AGRUPAMENTO_BALANCO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS','AGRUPAMENTO_BALANCO_TWEETS','TEM_TWITTER','TOP_BTWEETS','TOP_BSEG','TOP_TWEETS','TOP_SEG','TOP_VOTACAO','TOP_BENS','SCREEN_NAME','TWEET_COUNTS','MEDIA_RETWEETS','SOMA_RETWEETS','MEDIA_FAV','SOMA_FAV','CONSISTENCIA_TEMATICA','AGRUPAMENTO_cTEMATICA']\n",
    " \n",
    "coautoria_info = coautoria_info[keepcol]\n",
    "\n",
    "coautoria_info = coautoria_info.rename(columns={'SOURCE':'source','TARGET':'target'})\n",
    "\n",
    "coautoria_info.to_csv(\"grafo-coautoria.csv\", index=False)\n",
    "arq_semantico = \"grafo-coautoria.csv\"\n",
    "# len(tweets2020_info_rs)\n",
    "\n",
    "\n",
    "coautoria_info_rs= coautoria_info[(coautoria_info['ESTADO_ELEICAO']=='RS')]\n",
    "# len(coautoria_info_rs)\n",
    "\n",
    "coautoria_info_rs.to_csv(\"grafo-coautoria-rs.csv\", index=False)\n",
    "arq_semantico = \"grafo-coautoria-rs.csv\"\n",
    "\n",
    "coautoria_rs = pd.read_csv(\"grafo-coautoria-rs.csv\")\n",
    "lista_rs = list(coautoria_rs['source'].unique())\n",
    "\n",
    "\n",
    "coautoria_f_rs = coautoria_rs.query('target in @lista_rs')\n",
    "coautoria_f_rs.to_csv(\"grafo-coautoria-f-rs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcdb03-628c-42c8-9562-52e2b9cabf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0532219c-8d08-4e7e-8239-e5f3b5ee6120",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.7 - Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec95889-dbd7-4910-9be9-21a71f6023c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafo = 'grafo-coautoria-f-rs.csv'\n",
    "\n",
    "df = pd.read_csv(grafo)\n",
    "Graphtype = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df, create_using=Graphtype)\n",
    "\n",
    "Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "G = G.subgraph(Gcc[0])\n",
    "\n",
    "\n",
    "G.number_of_nodes()\n",
    "G.number_of_edges()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc54190-fa7c-4179-b61f-b55efdf1db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d3808-7a72-4434-b3c5-8a17b38be246",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(greedy_modularity_communities(G))\n",
    "# len(c)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39310571-80e4-458f-90b7-821a81d0dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = dict(nx.degree(G))\n",
    "# dict(degree_centrality)\n",
    "df = pd.DataFrame.from_dict(degree_centrality, orient='index')\n",
    "\n",
    "df.index.name = 'deputado'\n",
    "df= df.reset_index()\n",
    "df.rename(columns = {0:'grau'},inplace = True)\n",
    "\n",
    "\n",
    "df_info = pd.merge(df, usuarios_proposicoes_rs[['NOME_AUTOR','PARTIDO_ATUAL','IDEOLOGIA_PARTIDO_ATUAL','ST_REELEICAO','ESTADO_ELEICAO','REGIAO_ELEICAO','N_PLS','TWEET_COUNTS','MEDIA_RETWEETS','AGRUPAMENTO_BENS', 'AGRUPAMENTO_VOTOS', 'AGRUPAMENTO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS','TOP_TWEETS', 'TOP_SEG', 'TOP_VOTACAO', 'TOP_BENS']], left_on='deputado', right_on='NOME_AUTOR',how='inner')\n",
    "\n",
    "df_info = df_info.drop(['NOME_AUTOR'],axis=1)\n",
    "\n",
    "df_info = df_info.sort_values(by='grau', ascending=False)\n",
    "\n",
    "df_info= df_info.reset_index()\n",
    "\n",
    "df_info = df_info.drop(['index'],axis=1)\n",
    "# df_info[:10]\n",
    "df_info\n",
    "\n",
    "# df_info['N_PLS'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd420019-9e61-441e-b036-2287ad0938fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(betweenness_centrality, orient='index')\n",
    "\n",
    "betweenness_centrality = dict(nx.betweenness_centrality(G,normalized=False))\n",
    "# degree_centrality = dict(nx.degree(G))\n",
    "# dict(degree_centrality)\n",
    "df = pd.DataFrame.from_dict(betweenness_centrality, orient='index')\n",
    "\n",
    "df.index.name = 'deputado'\n",
    "df= df.reset_index()\n",
    "df.rename(columns = {0:'intermediacao'},inplace = True)\n",
    "\n",
    "\n",
    "df_info = pd.merge(df, usuarios_proposicoes_rs[['NOME_AUTOR','PARTIDO_ATUAL','IDEOLOGIA_PARTIDO_ATUAL','ST_REELEICAO','ESTADO_ELEICAO','REGIAO_ELEICAO','N_PLS','TWEET_COUNTS','MEDIA_RETWEETS','AGRUPAMENTO_BENS', 'AGRUPAMENTO_VOTOS', 'AGRUPAMENTO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS','TOP_TWEETS', 'TOP_SEG', 'TOP_VOTACAO', 'TOP_BENS']], left_on='deputado', right_on='NOME_AUTOR',how='inner')\n",
    "\n",
    "df_info = df_info.drop(['NOME_AUTOR'],axis=1)\n",
    "\n",
    "df_info = df_info.sort_values(by='intermediacao', ascending=False)\n",
    "\n",
    "df_info= df_info.reset_index()\n",
    "\n",
    "df_info = df_info.drop(['index'],axis=1)\n",
    "# df_info[:10]\n",
    "df_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ee16f-d810-446d-a670-5edda30b72cd",
   "metadata": {},
   "source": [
    "## 3.8 - Menção a proposições no Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3bae4-4096-4a15-8aa7-7133589ecf59",
   "metadata": {},
   "source": [
    "### 3.9 - Filtra tweets por menções de proposições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8c654-39ba-46d0-8c6a-9e0b12552f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = 'projeto de lei|requerimento de informação|projeto de decreto legislativo|projeto de lei complementar|medida provisória|projeto de resolução de alteração do regimento|projeto de lei de conversão|emenda|substitutivo do senado|proposta de emenda à constituição|solicitação de informação ao tcu|mensagem de indicação de líder|consulta|proposta de fiscalização e controle|requerimento de instituição de cpi| pl | ric  | inc | pdl | plp | mpv | prc | plv | ems | pec | sit | msc | con | pfc | rcp | projeto | proposicao'\n",
    "\n",
    "\n",
    "\n",
    "filtro_geral =tweets2020_info[tweets2020_info['text'].str.contains(pat)]\n",
    "\n",
    "filtro_rs =tweets2020_info_rs[tweets2020_info_rs['text'].str.contains(pat)]\n",
    "\n",
    "\n",
    "\n",
    "# tweets2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ed899-824e-43b0-967f-cedd2078ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtro_rs.to_csv(\"contsulta_rs.csv\")\n",
    "# filtro_geral.to_csv(\"contsulta_geral.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cd882-f5ca-4b06-8612-ee092202ee24",
   "metadata": {},
   "source": [
    "### 4.0 - Calcula a porcentagem para o âmbito geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820b2fa-4bf7-4b19-8d99-5b7d874eb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets2020_info)\n",
    "len(filtro_geral)\n",
    "uno = len(tweets2020_info)\n",
    "dos = len(filtro_geral)\n",
    "round(dos/uno*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25071606-dd92-4cc9-ab85-f6e50c2186bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtro_geral['NM_URNA'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21877c-d08b-4ed8-b1c2-e555b18ada1a",
   "metadata": {},
   "source": [
    "### 4.5 - Calcula a porcentagem para deputados gaúchos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923bfc0-f0e5-4f91-a0b8-d0d73987f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets2020_info_rs)\n",
    "len(filtro_rs)\n",
    "uno = len(tweets2020_info_rs)\n",
    "dos = len(filtro_rs)\n",
    "round(dos/uno*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292def1-34f6-4f3d-a23b-49255db2c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtro_rs['NM_URNA'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e58d849-aeba-4f26-bbf6-1ff932a9b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgx = 'projeto de lei\\s\\d*|requerimento de informação\\s\\d*|indicação\\s\\d*|projeto de decreto legislativo\\s\\d*|projeto de lei complementar\\s\\d*|medida provisória\\s\\d*|projeto de resolução de alteração do regimento\\s\\d*|projeto de lei de conversão\\s\\d*|emenda\\s\\d*|substitutivo do senado\\s\\d*|proposta de emenda à constituição\\s\\d*|solicitação de informação ao tcu\\s\\d*|mensagem de indicação de líder\\s\\d*|consulta\\s\\d*|proposta de fiscalização e controle\\s\\d*|requerimento de instituição de cpi\\s\\d*|pl\\s\\d*|ric \\s\\d*|inc\\s\\d*|pdl\\s\\d*|plp\\s\\d*|mpv\\s\\d*|prc\\s\\d*|plv\\s\\d*|ems\\s\\d*|pec\\s\\d*|sit\\s\\d*|msc\\s\\d*|con\\s\\d*|pfc\\s\\d*|rcp\\s\\d*|proposicao\\s\\d*|projeto\\s\\d*|lei\\s\\d*\\.\\d+'\n",
    "\n",
    "lista_rs  = list(tweets2020_info_rs['text'].apply(unidecode).str.lower())\n",
    "\n",
    "lista_geral = list(tweets2020_info['text'].apply(unidecode).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1817b-36b4-40d0-b2a9-a47d5376f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# newlist = list(filter(r.match, lista_rs)) \n",
    "# r = re.compile(rgx2)\n",
    "\n",
    "str_list_rs = \" \".join(lista_rs)\n",
    "str_list_geral = \" \".join(lista_geral)\n",
    "\n",
    "etapa_rs = re.findall(rgx,str_list_rs)\n",
    "etapa_geral = re.findall(rgx,str_list_geral)\n",
    "\n",
    "resultados_rs = [i for i in etapa_rs if any(map(str.isdigit, i))]\n",
    "resultados_geral = [i for i in etapa_geral if any(map(str.isdigit, i))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6b18d-3896-45ed-a7a5-44c58018d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resultados_geral)\n",
    "# resultados_geral\n",
    "len(resultados_rs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571d53f-ebc4-4823-841c-4fc447926c0f",
   "metadata": {},
   "source": [
    "### 4.6 - Gera Gráfico com menções a proposições - Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31424634-79b2-4c1b-93b4-e247bddb20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_rs = [i.strip() for i in resultados_rs]\n",
    "resultados_geral = [i.strip() for i in resultados_geral]\n",
    "\n",
    "contagem_geral = Counter(resultados_geral)\n",
    "contagem_geral = dict(contagem_geral)\n",
    "df = pd.DataFrame.from_dict(contagem_geral, orient='index')\n",
    "\n",
    "\n",
    "\n",
    "df = df.nlargest(6,[0])\n",
    "# df.nlargest(12,df[0]).sort_values(by=df[0], ascending=False)\n",
    "\n",
    "contagem_geral = df[0]\n",
    "# contagem_geral.drop([0])\n",
    "# contagem_geral.drop(contagem_geral.index[0])\n",
    "# type(contagem_geral)\n",
    "contagem_geral = contagem_geral.iloc[1:]\n",
    "contagem_geral = contagem_geral.sort_values(ascending=True)\n",
    "# contagem_geral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a670df-edf5-4bba-8abd-3ad5a464d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        \n",
    "top = contagem_geral.plot(kind='barh', \n",
    "                        colormap='tab10', \n",
    "                        figsize=(11, 8),width=0.8)\n",
    "\n",
    "for i, v in enumerate(list(contagem_geral)):\n",
    "    top.text(v+.1, i-0.1, v ,fontsize=15, color='black')\n",
    "\n",
    "plt.tick_params(axis='y', which='major', labelsize=14)\n",
    "    \n",
    "# top.margins(x=1)\n",
    "# top.spines['right'].set_visible(False)\n",
    "# top.spines['top'].set_visible(False)\n",
    "# top.spines['bottom'].set_visible(False)\n",
    "    \n",
    "# top.get_legend().remove()            \n",
    "\n",
    "# plt.rcParams.update(IPython_default);\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.grid(color='b', linestyle='-', linewidth=.1)    \n",
    "plt.savefig(\"novos-graficos/Figura x - Menção a proposições no Twitter- Geral.jpg\",bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a193a-888e-41e6-807a-1466317250b8",
   "metadata": {},
   "source": [
    "### 4.7 - Gera Gráfico com menções a proposições - Rio Grande do Sul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9760b-0489-4905-a12d-fce2eaa42b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_rs = Counter(resultados_rs)\n",
    "contagem_rs = dict(contagem_rs)\n",
    "df = pd.DataFrame.from_dict(contagem_rs, orient='index')\n",
    "\n",
    "\n",
    "\n",
    "df = df.nlargest(7,[0])\n",
    "# df.nlargest(12,df[0]).sort_values(by=df[0], ascending=False)\n",
    "\n",
    "contagem_rs = df[0]\n",
    "# contagem_rs.drop([0])\n",
    "# contagem_rs.drop(contagem_rs.index[0])\n",
    "# type(contagem_rs)\n",
    "contagem_rs = contagem_rs.iloc[1:]\n",
    "contagem_rs = contagem_rs.sort_values(ascending=True)\n",
    "contagem_rs = contagem_rs.drop(['pl 22'])\n",
    "contagem_rs\n",
    "# contagem_rs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f14d79-dd16-4bf7-bf8b-14769ecc30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "                        \n",
    "top = contagem_rs.plot(kind='barh', \n",
    "                        colormap='tab10', \n",
    "                        figsize=(11, 8),width=0.8)\n",
    "\n",
    "for i, v in enumerate(list(contagem_rs)):\n",
    "    top.text(v+0.08, i-0.1, v ,fontsize=15, color='black')\n",
    "\n",
    "plt.tick_params(axis='y', which='major', labelsize=14)\n",
    "    \n",
    "# top.margins(x=1)\n",
    "# top.spines['right'].set_visible(False)\n",
    "# top.spines['top'].set_visible(False)\n",
    "# top.spines['bottom'].set_visible(False)\n",
    "    \n",
    "# top.get_legend().remove()            \n",
    "\n",
    "# plt.rcParams.update(IPython_default);\n",
    "# plt.style.use(\"fivethirtyeight\")\n",
    "plt.grid(color='b', linestyle='-', linewidth=.1)    \n",
    "plt.savefig(\"novos-graficos/Figura x - Menção a proposições no Twitter- Rio Grande do Sul.jpg\",bbox_inches = 'tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad441ef-2dc1-4f18-937b-a8a02f246b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grafo de conexão do twitter filtrando por PLS - geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0bfc77-00e5-435b-ae08-91bb193bbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f79e42-1a45-4337-b1a0-77a5eb07b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro_geral.to_csv(\"filtro-geral.csv\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "filtro_rs.to_csv(\"filtro-rs.csv\",encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9715a-b892-4ccd-af37-4150a029b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filtro_geral.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c079b77-c6f1-4044-a655-550021726d95",
   "metadata": {},
   "source": [
    "## 4.8 - Rede de Tweets mencionando proposições "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167f9c7-b0c1-4ca4-81c4-3c611d461232",
   "metadata": {},
   "source": [
    "### 4.9 - Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc69ffe-7e09-465e-a32c-1498e7b17595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "arq = \"filtro-geral\"\n",
    "\n",
    "arq_json = arq + \".json\"\n",
    "arq_csv = arq + \".csv\"\n",
    "arq_grafo = arq + \"-grafo.csv\"\n",
    "arq_rt = arq + \"-grafo-rt.csv\"\n",
    "arq_mt = arq + \"-grafo-mt.csv\"\n",
    "\n",
    "outrow = []\n",
    "with open(arq_csv, \"r\",encoding=\"utf-8\") as fileIn:  # input file location\n",
    "    with open(arq_grafo, \"w\") as fileOut:  # output file location\n",
    "        writer = csv.writer(fileOut)\n",
    "        reader = csv.reader(fileIn, delimiter=',')\n",
    "        writer.writerow(['source','target', \"text\"])\n",
    "        for row in reader:\n",
    "            screen_name = row[0]    \n",
    "            text = row[1]      \n",
    "            target = ''\n",
    "            for cell in row:\n",
    "                target = re.findall(r\"@([^\\s]+)\", cell)\n",
    "                target = re.sub(r\"\\[|\\'|\\:|\\]\", '', str(target))\n",
    "                outrow \n",
    "            writer.writerow([screen_name, target, text])\n",
    "\n",
    "df = pd.read_csv(arq_grafo)\n",
    "df['target'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['target'], inplace=True)\n",
    "df.to_csv(arq_grafo, index=False)\n",
    "\n",
    "df = pd.read_csv(arq_grafo)\n",
    "rt = df['text'].str.startswith('RT @')\n",
    "df[rt].to_csv(arq_rt, index=False)\n",
    "df2 = pd.read_csv(arq_rt)\n",
    "df2['target'].replace(r\",[\\s\\S]*$\", \"\", regex=True, inplace= True)\n",
    "df2.to_csv(arq_rt, index=False)\n",
    "\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = df['target'].str.split(',').map(len)\n",
    "\n",
    "res = pd.DataFrame({'source': np.repeat(df['source'], lens),\n",
    "                    'target': chainer(df['target']),\n",
    "                    'text': np.repeat(df['text'], lens)\n",
    "                    })\n",
    "\n",
    "res['target'].replace('', np.nan, inplace=True)\n",
    "res.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "mt = ~res['text'].str.startswith('RT @')\n",
    "res[mt].to_csv(arq_mt, index=False)\n",
    "# os.remove(arq_grafo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f1bd1-cadc-4917-8c56-352955e9a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets2020[(tweets2020['screen_name']=='lpbragancabr')]\n",
    "# len(filtro_geral['NM_URNA'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b43fe-3f15-47e2-867a-002aeb427f2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.10 - Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310fbb7-50c6-42f2-83a9-7c1cb1fbf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafo = 'filtro-geral-grafo.csv'\n",
    "\n",
    "df = pd.read_csv(grafo)\n",
    "Graphtype = nx.DiGraph()\n",
    "G = nx.from_pandas_edgelist(df, create_using=Graphtype)\n",
    "\n",
    "# Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "# G = G.subgraph(Gcc[0])\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "G.number_of_nodes()\n",
    "G.number_of_edges()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5614f-92f5-4d4c-a8dc-32c437c7dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf9910-ba9b-49a1-91c6-6d594dfe4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_centrality = dict(G.in_degree())\n",
    "# dict(degree_centrality)\n",
    "df = pd.DataFrame.from_dict(degree_centrality, orient='index')\n",
    "\n",
    "df.index.name = 'deputado'\n",
    "\n",
    "df= df.reset_index()\n",
    "df.rename(columns = {0:'grau'},inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df_info = pd.merge(df, usuarios_proposicoes[['SCREEN_NAME','NOME_AUTOR','PARTIDO_ATUAL','IDEOLOGIA_PARTIDO_ATUAL','ST_REELEICAO','ESTADO_ELEICAO','REGIAO_ELEICAO','N_PLS','TWEET_COUNTS','MEDIA_RETWEETS','AGRUPAMENTO_BENS', 'AGRUPAMENTO_VOTOS', 'AGRUPAMENTO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS','TOP_TWEETS', 'TOP_SEG', 'TOP_VOTACAO', 'TOP_BENS']], left_on='deputado', right_on='SCREEN_NAME',how='inner')\n",
    "\n",
    "# df_info\n",
    "\n",
    "df_info = df_info.drop(['SCREEN_NAME'],axis=1)\n",
    "\n",
    "df_info = df_info.sort_values(by='grau', ascending=False)\n",
    "# df_info.shape[0]\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910b0ab-c37e-4b33-8e2f-4250aeef3f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_rs = df_info[(df_info['ESTADO_ELEICAO']=='RS')]\n",
    "df_info_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310bee7-4b00-4042-a7b4-5678f9704070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(betweenness_centrality, orient='index')\n",
    "\n",
    "betweenness_centrality = dict(nx.betweenness_centrality(G,normalized=False))\n",
    "# degree_centrality = dict(nx.degree(G))\n",
    "# dict(degree_centrality)\n",
    "df = pd.DataFrame.from_dict(betweenness_centrality, orient='index')\n",
    "\n",
    "df.index.name = 'deputado'\n",
    "df= df.reset_index()\n",
    "df.rename(columns = {0:'intermediacao'},inplace = True)\n",
    "\n",
    "df_info = pd.merge(df, usuarios_proposicoes[['SCREEN_NAME','NOME_AUTOR','PARTIDO_ATUAL','IDEOLOGIA_PARTIDO_ATUAL','ST_REELEICAO','ESTADO_ELEICAO','REGIAO_ELEICAO','N_PLS','TWEET_COUNTS','MEDIA_RETWEETS','AGRUPAMENTO_BENS', 'AGRUPAMENTO_VOTOS', 'AGRUPAMENTO_SEGUIDORES','AGRUPAMENTO_NUMERO_TWEETS','TOP_TWEETS', 'TOP_SEG', 'TOP_VOTACAO', 'TOP_BENS']], left_on='deputado', right_on='SCREEN_NAME',how='inner')\n",
    "\n",
    "# df_info\n",
    "\n",
    "df_info = df_info.drop(['SCREEN_NAME'],axis=1)\n",
    "\n",
    "df_info = df_info.sort_values(by='intermediacao', ascending=False)\n",
    "# df_info.shape[0]\n",
    "df_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bf627d-b45a-4b66-b2d0-51328f6956af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info_rs = df_info[(df_info['ESTADO_ELEICAO']=='RS')]\n",
    "df_info_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343cb15-fd50-4d6d-af83-f7902c090ce5",
   "metadata": {},
   "source": [
    "### 4.11 - Publicações mais compartilhadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64afadea-e3e3-4598-8ad8-dc7c284f3f7e",
   "metadata": {},
   "source": [
    "#### 4.12 - Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0112d-6a43-441f-a2b2-40025f6e6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtro_geral.head(2)\n",
    "topTweets = filtro_geral.nlargest(3,'retweet_count')\n",
    "# tweetsTop10\n",
    "topIds = topTweets['id'].astype(\"str\").values.tolist()\n",
    "\n",
    "string = \"https://twitter.com/OReillyMedia/status/\"\n",
    "\n",
    "topIds = [string + s for s in topIds]\n",
    "# topIds\n",
    "\n",
    "class Tweet(object):\n",
    "    def __init__(self, s, embed_str=False):\n",
    "        if not embed_str:\n",
    "            # Use Twitter's oEmbed API\n",
    "            # https://dev.twitter.com/web/embedded-tweets\n",
    "            api = 'https://publish.twitter.com/oembed?url={}'.format(s)\n",
    "            response = requests.get(api)\n",
    "            self.text = response.json()[\"html\"]\n",
    "        else:\n",
    "            self.text = s\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return self.text\n",
    "\n",
    "# Tweet(\"https://twitter.com/OReillyMedia/status/1253710046405500928\")\n",
    "    \n",
    "for x in topIds:\n",
    "    Tweet(x)\n",
    "# vTweets(topIds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1efd0-89cb-46d9-906a-ff008aa2303c",
   "metadata": {},
   "source": [
    "#### 4.13 - Rio Grande do Sul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f5e56-94d8-41a7-998b-3ab5450e7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "topTweets = filtro_rs.nlargest(3,'retweet_count')\n",
    "# tweetsTop10\n",
    "topIds = topTweets['id'].astype(\"str\").values.tolist()\n",
    "\n",
    "string = \"https://twitter.com/OReillyMedia/status/\"\n",
    "\n",
    "topIds = [string + s for s in topIds]\n",
    "# topIds\n",
    "\n",
    "class Tweet(object):\n",
    "    def __init__(self, s, embed_str=False):\n",
    "        if not embed_str:\n",
    "            # Use Twitter's oEmbed API\n",
    "            # https://dev.twitter.com/web/embedded-tweets\n",
    "            api = 'https://publish.twitter.com/oembed?url={}'.format(s)\n",
    "            response = requests.get(api)\n",
    "            self.text = response.json()[\"html\"]\n",
    "        else:\n",
    "            self.text = s\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return self.text\n",
    "\n",
    "# Tweet(\"https://twitter.com/OReillyMedia/status/1253710046405500928\")\n",
    "    \n",
    "for x in topIds:\n",
    "    Tweet(x)\n",
    "# vTweets(topIds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
