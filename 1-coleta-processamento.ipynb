{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>0 - Setup do sistema</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\"><b>0.2 - Importação dos módulos</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import decimal\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from fuzzywuzzy import process\n",
    "import gspread\n",
    "import tweepy \n",
    "from tweepy import OAuthHandler\n",
    "import time\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "import sys\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import codecs\n",
    "import os.path\n",
    "from os.path import join as pjoin\n",
    "import glob\n",
    "import json\n",
    "from io import StringIO\n",
    "from io import open\n",
    "from urllib.request import urlopen\n",
    "from itertools import chain\n",
    "import os\n",
    "import csv\n",
    "import regex as re\n",
    "from csv import DictReader\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community import girvan_newman\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.readwrite import json_graph\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import logging\n",
    "import codecs\n",
    "from os.path import join as pjoin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">0.4 - Declaração das chaves de API do Twitter</h3>\n",
    "\n",
    "<p>É preciso requisitá-las na <a href=\"https://developer.twitter.com/en/portal/petition/academic/is-it-right-for-you\">página de desenvolvedores da plataforma.</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_token, access_token_secret) \n",
    "api = tweepy.API(auth) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">0.5 - Download dos dados da Câmara dos Deputados e do Tribunal Superior Eleitoral</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%;border: 1px solid black; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <th style=\"width:100%;border: 1px solid black; border-collapse: collapse\">Câmara</th>\n",
    "    <th style=\"width:100%;border: 1px solid black; border-collapse: collapse\">TSE</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td style=\"width:100%;border: 1px solid black; border-collapse: collapse\"><a href=\"https://dadosabertos.camara.leg.br/arquivos/deputados/csv/deputados.csv\">deputados</a></td>\n",
    "    <td style=\"width:100%;border: 1px solid black; border-collapse: collapse\"><a href=\"https://cdn.tse.jus.br/estatistica/sead/odsele/consulta_cand/consulta_cand_2018.zip\">candidatos2018</a></td>\n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td style=\"width:100%;border: 1px solid black; border-collapse: collapse\"><a href=\"https://dadosabertos.camara.leg.br/arquivos/proposicoes/csv/proposicoes-2020.csv\">proposicoes</a></td>  \n",
    "    <td style=\"width:100%;border: 1px solid black; border-collapse: collapse\"><a href=\"https://cdn.tse.jus.br/estatistica/sead/odsele/bem_candidato/bem_candidato_2018.zip\">bensCandidatos2018</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width:100%;border: 1px solid black; border-collapse: collapse\"><a href=\"https://dadosabertos.camara.leg.br/arquivos/votacoesProposicoes/csv/votacoesProposicoes-2020.csv\">votacoesProposicoes</a></td>\n",
    "    </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td style=\"width:100%;border: 1px solid black; border-collapse: collapse\"><a href=\"https://dadosabertos.camara.leg.br/arquivos/proposicoesAutores/csv/proposicoesAutores-2020.csv\">proposicoesAutores</a></td>  \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">0.6 - Significado dos sufixos</h3>\n",
    "<ul>\n",
    "    <li>Dataframe_F: base proveniente de filtro </li>\n",
    "    <li>Dataframe_M: base proveniente de pareamento (merge)</li>\n",
    "    <li>Dataframe_G: base proveniente de agrupamento (grouby)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1 - Importação dos dados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\"><b>1.1 - Carregamento de dados referentes à deputados, proposições, votações e frentes parlamentares</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoes = pd.read_csv(\"dados-camara/2020/originais/proposicoes-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "proposicoesAutores = pd.read_csv(\"dados-camara/2020/originais/proposicoesAutores-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "proposicoesTemas = pd.read_csv(\"dados-camara/2020/originais/proposicoesTemas-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoes = pd.read_csv(\"dados-camara/2020/originais/votacoes-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoesOrientacoes = pd.read_csv(\"dados-camara/2020/originais/votacoesOrientacoes-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoesProposicoes = pd.read_csv(\"dados-camara/2020/originais/votacoesProposicoes-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoesVotos = pd.read_csv(\"dados-camara/2020/originais/votacoesVotos-2020.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "frentesDeputados = pd.read_csv(\"dados-camara/2020/originais/frentesDeputados.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "deputados =  pd.read_csv(\"dados-camara/2020/originais/deputados.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">1.2 - Listagem de colunas das bases</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proposicoes.columns\n",
    "# list(proposicoesAutores.columns)\n",
    "list(proposicoesTemas.columns)\n",
    "# list(votacoes.columns)\n",
    "# list(votacoesOrientacoes.columns)\n",
    "# list(votacoesProposicoes.columns)\n",
    "# list(votacoesVotos.columns)\n",
    "# list(frentesDeputados.columns)\n",
    "# list(deputados.columns)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">1.3 - Remoção de colunas não usadas na análise</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoes_F1 = proposicoes.drop(['ultimoStatus_dataHora','ultimoStatus_uriRelator','ultimoStatus_idOrgao','ultimoStatus_siglaOrgao','ultimoStatus_uriOrgao','ultimoStatus_regime','ultimoStatus_idSituacao','ultimoStatus_url','codTipo','siglaTipo','ementaDetalhada','dataApresentacao','urlInteiroTeor','ultimoStatus_idTipoTramitacao'], axis = 1)\n",
    "proposicoesAutores_F1 = proposicoesAutores.drop(['proponente','uriAutor','uriPartidoAutor','uriProposicao','ordemAssinatura'], axis = 1)\n",
    "proposicoesTemas_F1 = proposicoesTemas2020.drop(['siglaTipo','numero','ano','codTema','relevancia'], axis = 1)\n",
    "votacoes_F1 = votacoes.drop(['dataHoraRegistro','idOrgao','uriOrgao','siglaOrgao','idEvento','uriEvento','ultimaAberturaVotacao_dataHoraRegistro','ultimaApresentacaoProposicao_dataHoraRegistro','ultimaApresentacaoProposicao_uriProposicao','ultimaApresentacaoProposicao_descricao','ultimaAberturaVotacao_descricao'], axis = 1)\n",
    "votacoesOrientacoes_F1 = votacoesOrientacoes2020.drop(['uriVotacao','siglaOrgao'], axis = 1)\n",
    "votacoesProposicoes_F1 = votacoesProposicoes2020.drop(['uriVotacao','proposicao_codTipo'], axis = 1)\n",
    "votacoesVotos_F1 = votacoesVotos.drop(['uriVotacao','deputado_uri','deputado_uriPartido','deputado_urlFoto','dataHoraVoto'], axis = 1)\n",
    "frentesDeputados_F1 = frentesDeputados.drop(['deputado_.uri','deputado_.urlFoto','deputado_.codTitulo','dataInicio','dataFim','deputado_.uriPartido','deputado_.siglaUf','deputado_.urlFoto','deputado_.codTitulo','deputado_.uriPartido','deputado_.uri','deputado_.idLegislatura','dataInicio','dataFim','id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">1.4 - Arquivamento de bases filtradas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoes_F1.to_csv(\"dados-camara/2020/modificados/proposicoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "proposicoesAutores_F1.to_csv(\"dados-camara/2020/modificados/proposicoesAutores-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "proposicoesTemas_F1.to_csv(\"dados-camara/2020/modificados/proposicoesTemas-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "votacoes_F1.to_csv(\"dados-camara/2020/modificados/votacoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "votacoesOrientacoes_F1.to_csv(\"dados-camara/2020/modificados/votacoesOrientacoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "votacoesProposicoes_F1.to_csv(\"dados-camara/2020/modificados/votacoesProposicoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "votacoesVotos_F1.to_csv(\"dados-camara/2020/modificados/votacoesVotos-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)\n",
    "frentesDeputados_F1.to_csv(\"dados-camara/2020/modificados/frentesDeputados-2020-F1.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">1.5 - Carregamento das bases filtradas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoes_F1 = pd.read_csv(\"dados-camara/2020/modificados/proposicoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "proposicoesAutores_F1 = pd.read_csv(\"dados-camara/2020/modificados/proposicoesAutores-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "proposicoesTemas_F1 = pd.read_csv(\"dados-camara/2020/modificados/proposicoesTemas-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoes_F1 = pd.read_csv(\"dados-camara/2020/modificados/votacoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoesOrientacoes_F1 = pd.read_csv(\"dados-camara/2020/modificados/votacoesOrientacoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoesProposicoes_F1 = pd.read_csv(\"dados-camara/2020/modificados/votacoesProposicoes-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "votacoesVotos_F1 = pd.read_csv(\"dados-camara/2020/modificados/votacoesVotos-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "frentesDeputados_F1 = pd.read_csv(\"dados-camara/2020/modificados/frentesDeputados-2020-F1.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "deputados = pd.read_csv(\"dados-camara/2020/originais/deputados.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">1.6 - Listagem de colunas das bases filtradas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(proposicoes2020_F1.columns)\n",
    "list(proposicoesAutores2020_F1.columns)\n",
    "list(proposicoesTemas2020_F1.columns)\n",
    "list(votacoes2020_F1.columns)\n",
    "list(votacoesOrientacoes2020_F1.columns)\n",
    "list(votacoesProposicoes2020_F1.columns)\n",
    "list(votacoesVotos2020_F1.columns)\n",
    "list(frentesDeputados_F1.columns)\n",
    "list(deputados.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 - Processamento da base de dados \"listaDeputados\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.1 - Filtragem da base do TSE para pegar apenas deputados federais</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votacao = pd.read_csv(\"votacao_candidato_munzona_2018_BRASIL.csv\", sep=\";\", encoding=\"iso-8859-1\")\n",
    "filtroVotacao = votacao[(votacao.DS_CARGO=='Deputado Federal')&(votacao.DS_SIT_TOT_TURNO.str.startswith(\"ELEITO\"))]\n",
    "filtroVotacao.to_csv(\"deputados-2018.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.2 - Agrupamento de informações do TSE para obter registros únicos e números totais de votos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votacaoFiltrado = pd.read_csv(\"deputados-2018.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "filtroVotacao2 = votacaoFiltrado.groupby(['NM_CANDIDATO']).agg({'NM_URNA_CANDIDATO':'first','SG_PARTIDO':'first', 'DS_COMPOSICAO_COLIGACAO':'first', 'SG_UF':'first', 'NM_MUNICIPIO':'first','QT_VOTOS_NOMINAIS':'sum'})\n",
    "filtroVotacao2.to_csv(\"2deputados-2018.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.3 - Filtragem da base do TSE para pegar apenas deputados federais suplentes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votacao = pd.read_csv(\"votacao_candidato_munzona_2018_BRASIL.csv\", sep=\";\", encoding=\"iso-8859-1\")\n",
    "filtroVotacao = votacao[(votacao.DS_CARGO=='Deputado Federal')&(votacao.DS_SIT_TOT_TURNO.str.startswith(\"SUPLENTE\"))]\n",
    "filtroVotacao2 = filtroVotacao.groupby(['NM_CANDIDATO']).agg({'NM_URNA_CANDIDATO':'first','SG_PARTIDO':'first', 'DS_COMPOSICAO_COLIGACAO':'first', 'SG_UF':'first', 'NM_MUNICIPIO':'first','QT_VOTOS_NOMINAIS':'sum'})\n",
    "filtroVotacao2.to_csv(\"suplentes-2018.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.4 - Exportação de informações sobre suplentes que assumiram titularidade</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efetivados = pd.read_csv(\"suplentes-tse-2018.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "filtroEfetivados = efetivados[(efetivados.NM_CANDIDATO.isin([\"AELTON JOSÉ DE FREITAS\", \"BEATRIZ ROSALIA RIBEIRO CAVASSA DE OLIVEIRA\", \"HILKEA CARLA DE SOUZA MEDEIROS LIMA\", \"DAVID MICHAEL DOS SANTOS MIRANDA\", \"RONALDO SANTINI\", \"FRANCISCO DANILO BASTOS FORTE\", \"JOSEILDO RIBEIRO RAMOS\", \"LEONARDO CUNHA DE BRITO\", \"MARCELO DE BRUM DA COSTA\", \"MARCOS BEZERRA RIBEIRO SOARES\", \"PAULO SÉRGIO PARANHOS DE MAGALHÃES\", \"PEDRO AUGUSTO PALARETI\", \"EVANDRO ROGERIO ROMAN\", \"REINHOLD STEPHANES JUNIOR\", \"JOÃO BATISTA CONTI\", \"PEDRO TORRES BRANDÃO VILELA\", \"VIVIANE DA COSTA REIS\", \"NEUCIMAR FERREIRA FRAGA\", \"JOSIVALDO DOS SANTOS MELO\", \"MILTON COELHO DA SILVA NETO\"]))]\n",
    "filtroEfetivados.to_csv(\"efetivados.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.6 - Pareamento entre base de dados e lista da Auditoria Cidadã com função da biblioteca fuzzywuzzy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tse = pd.read_csv(\"deputados-eleitos-tse.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "auditoria = pd.read_csv(\"perfis-auditoria-cidada.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "deputados = pd.read_csv(\"deputados-camara.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "tse = tse.sort_values('Nome_Parlamentar')\n",
    "auditoria = auditoria.sort_values('Nome_Parlamentar')\n",
    "\n",
    "choices = auditoria['Nome_Parlamentar'].values.tolist()\n",
    "tse['xNome_Parlamentar'] = tse['Nome_Parlamentar'].apply(lambda x: process.extractOne(x, choices)[0])\n",
    "\n",
    "tabela1 = tse.merge(auditoria, left_on='xNome_Parlamentar', right_on='Nome_Parlamentar')\n",
    "tabela2 = pd.merge(tabela1, deputados, how='left', left_on=['NM_CANDIDATO'], right_on=['nomeCivil'])\n",
    "tabela2.to_csv(\"pareamento-perfis-5.csv\", sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.7 - Busca de perfis oficiais no Twitter</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 5\n",
    "\n",
    "fileOut = open('results.txt', \"w\",encoding='utf-8')\n",
    "\n",
    "with open('deputados.csv', \"r\",encoding='utf-8') as fileIn: \n",
    "    \n",
    "    nomes = fileIn.readlines()\n",
    "    for n in nomes:\n",
    "        # fileOut.write(\"Gol---\"+n)\n",
    "        usersI = api.search_users(n, count)\n",
    "        usersM = [user.screen_name for user in usersI]  \n",
    "        print(str(usersM))\n",
    "        print(str(usersM), file=fileOut)\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.8 - Coleta do número de seguidores e de publicações dos perfis oficiais</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=open(\"results.txt\",\"w\",encoding='utf-8',newline='')\n",
    "\n",
    "with open('users.txt', \"r\",encoding='utf-8',newline='') as fileIn: \n",
    "    users = fileIn.readlines()\n",
    "    for user_name in users:\n",
    "        user = api.get_user(screen_name = user_name)\n",
    "        bio = str(user.description)\n",
    "        bio = re.sub(r\"\\n|\\\\n|\\n\\n|\\n\\n\\n\",\" \",bio)\n",
    "        bio = re.sub(\";\",\",\",bio)\n",
    "        print(user.screen_name,';',user.id,';',user.followers_count,';',user.statuses_count,';',bio, file=stats)\n",
    "        print(user.screen_name)\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.9 - Pareamento de dados da Câmara e do TSE com os do Twiitter</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1 = pd.read_csv(\"db-deputados-1.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "tse2018 = pd.read_csv(\"tse-2018.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "tabela2 = pd.merge(tabela1, tse2018, how='left', left_on=['CPF'], right_on=['NR_CPF_CANDIDATO'])\n",
    "tabela2.to_csv(\"db-deputados-2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.10 - Agrupamento e soma de valores referentes a declaração de bens dos deputados em 2018.</h3>\n",
    "<p>Centavos precisaram ser arredondados para completar esta função</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bensTse2018 = pd.read_csv(\"tse-bens-2018-1.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "# bensTse2018.shape[0]\n",
    "# list(bensTse2018.columns)\n",
    "\n",
    "bensTse2018['VR_BEM_CANDIDATO'] = bensTse2018['VR_BEM_CANDIDATO'].round(0).astype(int)\n",
    "\n",
    "somaBens2018 = bensTse2018.groupby(['SQ_CANDIDATO']).agg({'VR_BEM_CANDIDATO':'sum'})\n",
    "somaBens2018.to_csv(\"soma-bens-2018.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.11 - Pareamento da base de dados com as declarações de bens do TSE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1 = pd.read_csv(\"db-deputados-24-1.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "somaBens2018 = pd.read_csv(\"soma-bens-2018.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "tabela2 = pd.merge(tabela1, somaBens2018, how='left', left_on=['SQ_CANDIDATO'], right_on=['SQ_CANDIDATO'])\n",
    "\n",
    "tabela2.to_csv(\"db-deputados-25.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.12 - Pareamento da base de dados com lista de ideologia dos partidos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1 = pd.read_csv(\"db-deputados-25.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "ideologiaPartidos = pd.read_csv(\"ideologia-partidos.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "tabela2 = pd.merge(tabela1.astype(\"str\"), ideologiaPartidos.astype(\"str\"), how='left', left_on=['PARTIDO_ATUAL'], right_on=['PARTIDO'])\n",
    "\n",
    "tabela2.to_csv(\"db-deputados-26.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">2.13 - Pareamento da base de dados com lista da divisão territorial do Brasil</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela1 = pd.read_csv(\"db-deputados-26.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "regioes = pd.read_csv(\"regioes.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "tabela2 = pd.merge(tabela1, regioes, how='left', left_on=['ESTADO_ELEICAO'], right_on=['ESTADO'])\n",
    "tabela2.to_csv(\"db-deputados-27.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3 - Processamento da base de dados \"proposicoes\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">3.1 - Pareamento e filtragem das bases de proposições e autores de proposições</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoes_M = proposicoes_F1.merge(proposicoesAutores2020_F1,how='left',left_on='id', right_on='idProposicao').merge(proposicoesTemas2020_F1,how='left',left_on='id', right_on='idProposicao')\n",
    "proposicoes_MF = proposicoes_M.drop(['Unnamed: 0_x','Unnamed: 0_y','idProposicao_y','siglaTipo_y','numero_y', 'ano_y','Unnamed: 0','codTema','relevancia','codTipo','uriOrgaoNumerador', 'urnFinal', 'ultimoStatus_dataHora', 'ultimoStatus_sequencia','ultimoStatus_idOrgao', 'ultimoStatus_siglaOrgao','ultimoStatus_uriRelator',  'ultimoStatus_uriOrgao', 'ultimoStatus_regime', 'ultimoStatus_idTipoTramitacao', 'ultimoStatus_idSituacao', 'ultimoStatus_despacho', 'ultimoStatus_url', 'ordemAssinatura','uriAutor','uriPartidoAutor', 'idProposicao_x', 'uriProposicao','codTipoAutor','proponente','relevancia','codTema'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">3.2 - Agrupamento de informações referentes às proposições</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoesM.shape[0]\n",
    "unico = proposicoesM['id'].unique()\n",
    "unico.shape[0]\n",
    "proposicoes_GMF = proposicoes_MF.astype('str').groupby('id').agg({'uri': 'first','siglaTipo_x': 'first','numero_x':'first','ano_x': 'first','descricaoTipo': 'first','ementa': 'first','ementaDetalhada': 'first','keywords': 'first','dataApresentacao' : 'first','uriPropAnterior': 'first','uriPropPrincipal': 'first','uriPropPosterior': 'first','urlInteiroTeor': 'first','ultimoStatus_descricaoTramitacao':'first','ultimoStatus_descricaoSituacao': 'first','idDeputadoAutor': lambda tags: ','.join(tags),'tipoAutor': 'first','nomeAutor': lambda tags: ','.join(tags),'siglaPartidoAutor': lambda tags: ','.join(tags),'siglaUFAutor': lambda tags: ','.join(tags),'tema':'first'})\n",
    "# proposicoesG.shape[0]\n",
    "proposicoes_GMF.to_csv(\"dados-camara/2020/modificados/proposicoes-G.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposicoes = pd.read_csv(\"db-proposicoes.csv\")\n",
    "proposicoes['NOME_AUTOR'] = proposicoes['NOME_AUTOR'].astype(\"str\").apply(lambda x: ','.join(set(x.split(','))))\n",
    "proposicoes.to_csv(\"db-proposicoes.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4 - Processamento das bases de dados \"votosDeputados\" e \"votacoes\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">4.1 - Agrupamento das bases de orientações e votos a partir de coluna concatenada</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votacoesOrientacoes_F1['idVotacaoPartido'] =  votacoesOrientacoes_F1['idVotacao'] + votacoesOrientacoes_F1['siglaBancada']\n",
    "# votacoesOrientacoes['idVotacaoPartido'].unique().shape[0]\n",
    "votacoesVotos_F1['idVotacaoPartido'] = votacoesVotos_F1['idVotacao'] + votacoesVotos_F1['deputado_siglaPartido']\n",
    "# votacoesVotos['idVotacaoPartido'].unique().shape[0]\n",
    "votacoesVotos_F1['idProposicao'] = votacoesVotos_F1['idVotacao'].astype('str').replace(\"\\-(.*)\",\"\",regex=True)\n",
    "votacoesOrientacoes_F1['idProposicao'] = votacoesOrientacoes_F1['idVotacao'].astype('str').replace(\"\\-(.*)\",\"\",regex=True)\n",
    "votacoesProposicoes_F1['idProposicao'] = votacoesProposicoes_F1['idVotacao'].astype('str').replace(\"\\-(.*)\",\"\",regex=True)\n",
    "votosOrientacoes_M = votacoesVotos_F1.merge(votacoesOrientacoes_F1,how='left',on='idVotacaoPartido')\n",
    "# votosOrientacoes_MF = votosOrientacoes_M.drop(['Unnamed: 0_x', 'Unnamed: 0_y', 'idVotacao_y', 'uriVotacao_y', 'deputado_siglaPartido', 'deputado_uriPartido','deputado_idLegislatura', 'deputado_urlFoto','idVotacaoPartido', 'uriBancada','deputado_uri', 'siglaOrgao'],axis=1)\n",
    "print(votosOrientacoes_M.shape[0],votosOrientacoes_M['idProposicao_x'].unique().shape[0])\n",
    "\n",
    "votacoesProposicoes_M = votacoes_F1.merge(votacoesProposicoes_F1,how='left',left_on='id', right_on='idVotacao')\n",
    "votacoes_MF = votacoesProposicoes_M.drop(['Unnamed: 0_x', 'Unnamed: 0_y', 'data_y', 'descricao_y', 'dataHoraRegistro', 'idOrgao', 'uriOrgao', 'siglaOrgao', 'idEvento', 'uriEvento','ultimaAberturaVotacao_dataHoraRegistro', 'ultimaAberturaVotacao_descricao', 'ultimaApresentacaoProposicao_dataHoraRegistro', 'ultimaApresentacaoProposicao_descricao', 'ultimaApresentacaoProposicao_idProposicao','ultimaApresentacaoProposicao_uriProposicao','idVotacao', 'uriVotacao','proposicao_codTipo'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"font-style:italic\">4.2 - Pareamento da base \"votosDeputados\" com resultadosVotacoes\" e deputados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1resultadoVotacoes = pd.read_csv(\"planilha-google/v0-resultadoVotacoes.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "v0proposicoes = pd.read_csv(\"planilha-google/v0-proposicoes.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "v0deputados = pd.read_csv(\"planilha-google/v0-deputados.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "v0votosDeputados = pd.read_csv(\"planilha-google/v0-0-votosDeputados.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "v1votosDeputados = v0votosDeputados.merge(v1resultadoVotacoes,how='left',on='ID_VOTACAO')\n",
    "v1votosDeputados = v1votosDeputados[v1votosDeputados['APROVACAO'].notna()]\n",
    "v2votosDeputados = v1votosDeputados.astype('str').merge(v0deputados.astype('str'),how='left',left_on='ID_DEPUTADO', right_on='ID_CAMARA')\n",
    "v2votosDeputados['ID_PROPOSICAO'] = v2votosDeputados['ID_PROPOSICAO'].astype('str').str.replace('.0','')\n",
    "\n",
    "\n",
    "v3votosDeputados = pd.merge(v2votosDeputados.astype('str'),v0proposicoes[['ID','TEMA','PALAVRAS_CHAVE','EMENTA']].astype('str'), how='left', left_on=['ID_PROPOSICAO'], right_on=['ID'])\n",
    "\n",
    "\n",
    "v4votosDeputados = v3votosDeputados.drop(['EMENTA_PROPOSICAO','VOTOS_SIM','VOTOS_NAO','VOTOS_OUTROS','DESCRICAO','TIPO_PROPOSICAO','NUMERO_PROPOSICAO','ANO_PROPOSICAO','URL_VOTACAO','URL_PROPOSICAO','DATA_VOTO','NM_COMPLETO','IDADE','COLIGACAO_ELEICAO','EXPERIENCIA_DEP','CIDADE_NASC','ESTADO_NASC','ELEITO_POR','ST_DECLARAR_BENS','TELEFONE','EMAIL','WEBSITE','MIDIAS_SOCIAIS','TEM_TWITTER','LINK_TWITTER','SEGUIDORES_E1','BALANÇO_SEGUIDORES','TWEETS_E1','TWEETS_E2','BALANÇO_TWEETS','ID_TWITTER','SQ_CANDIDATO','NR_TITULO_ELEITORAL','CPF','ID_CAMARA','API_CAMARA','FOTO','LEG_FINAL','LEG_INICIAL','CONDICAO_ELEITORAL','SITUACAO','PARTIDO_ELEICAO','DT_NASCIMENTO','SG_BANCADA'],axis=1)\n",
    "\n",
    "\n",
    "v5votosDeputados = v4votosDeputados[v4votosDeputados['TEMA'].notna()]\n",
    "\n",
    "# list(v4votosDeputados.columns)\n",
    "v5votosDeputados.to_csv(\"planilha-google/v0-4-votosDeputados.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "print(v4votosDeputados.shape[0],v4votosDeputados['ID_PROPOSICAO'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votosDeputados = pd.read_csv(\"db-votosDeputados.csv\")\n",
    "votosDeputados = votosDeputados[votosDeputados['TEMA'].notna()]\n",
    "votosDeputados.to_csv(\"db-votosDeputados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5 - Processamento da base de dados \"tweetsDeputados\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 style=\"font-style:italic\">5.1 - Coleta de publicações dos perfis oficiais</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "api = tweepy.API(auth, retry_count=5, retry_delay=5, timeout=150, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "def json_format(data_json, current_tweet):\n",
    "    current_tweet['id'] = data_json.id\n",
    "    current_tweet['created_at'] = data_json.created_at.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    current_tweet['username'] = data_json.user.name\n",
    "    try:\n",
    "        #media = json.loads(data_json.entities['media'])\n",
    "        current_tweet['media_type'] = data_json.entities['media'][0]['type']\n",
    "        current_tweet['has_media'] = 'True'\n",
    "        #print json.dumps(media)\n",
    "    except:\n",
    "        current_tweet['has_media'] = 'False'\n",
    "        current_tweet['media_type'] = 'None'\n",
    "    current_tweet['screen_name'] = data_json.user.screen_name\n",
    "    current_tweet['retweet_count'] = data_json.retweet_count\n",
    "    current_tweet['favorite_count'] = data_json.favorite_count\n",
    "    current_tweet['full_text'] = data_json.text\n",
    "    current_tweet['lang'] = data_json.lang\n",
    "    return\n",
    "\n",
    "def gather(api):\n",
    "    try:\n",
    "        user_id = api.get_user(perfil).id\n",
    "    except tweepy.error.TweepError:\n",
    "        print('User not found.')\n",
    "        sys.exit(0)\n",
    "\n",
    "    if perfil:\n",
    "        fname = perfil + '.json'\n",
    "        dataset_file = open(fname, 'w', encoding='utf8')\n",
    "    else:\n",
    "        fname = perfil + '.json'\n",
    "        dataset_file = open(fname, 'w', encoding='utf8')\n",
    "\n",
    "    dataset_file.write('[')\n",
    "    current_tweet = {}\n",
    "    dados = api.home_timeline()\n",
    "    last_id = int(str(json.dumps(dados[0]._json))[55:74])\n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            new_tweets = api.user_timeline(id = user_id, count = 200, max_id=str(last_id-1))\n",
    "            if not new_tweets:\n",
    "                dataset_file.write(']')\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                if counter != 0:\n",
    "                    dataset_file.write(',')\n",
    "                json_format(tweet, current_tweet)\n",
    "                dataset_file.write(json.dumps(current_tweet, ensure_ascii=False))\n",
    "                dataset_file.write('\\n')\n",
    "                counter+=1\n",
    "                if sys.stdout.isatty():\n",
    "                    print(\"\\rNumber of tweets collected so far...: %i\"%counter, end='\\r', flush=True)\n",
    "                else:\n",
    "                    print(counter, end=' ', flush=True)\n",
    "\n",
    "            last_id = new_tweets[-1].id\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "    print(\"\\nAll done. Output written to \" + fname)\n",
    "    dataset_file.close()\n",
    "    time.sleep(5.5)\n",
    "\n",
    "with open('perfis-0.csv', \"r\",encoding='utf-8',newline='') as fileIn: \n",
    "    lista_perfis = fileIn.read().split('\\n')\n",
    "    for perfil in lista_perfis:\n",
    "        perfil = perfil.rstrip()\n",
    "        gather(api)\n",
    "        time.sleep(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-style:italic\">5.2 - Processamento da primeira coleta de publicações oficiais</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = 'dados-twitter/publicacoes/A-29-12-2020\\\\' \n",
    "json_pattern = os.path.join(path_to_json,'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "# print(chr(92))\n",
    "for file in file_list:\n",
    "    data = pd.read_json(file)    \n",
    "    dfs.append(data)\n",
    "\n",
    "tweets_c1 = pd.concat(dfs, ignore_index=True)\n",
    "tweets_c1['coleta'] = \"C1\"\n",
    "# tweets_c1.head(5)\n",
    "# tweets_c1.shape[0]\n",
    "# tweets_c1['text'].unique().shape[0]\n",
    "tweetsC1_F1 = tweets_c1[(tweets_c1['created_at'] > '2020-01-01 00:00:00')]\n",
    "tweetsC1_F1.shape[0]\n",
    "tweetsC1_F1.to_csv(\"dados-twitter/tweetsC1_F1.csv\", sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "arq = \"dados-twitter/tweetsDeputados-F\"\n",
    "arq_csv = arq + \".csv\"\n",
    "arq_grafo = arq + \"-grafo.csv\"\n",
    "arq_rt = arq + \"-grafo-rt.csv\"\n",
    "arq_mt = arq + \"-grafo-mt.csv\"\n",
    "arq_hashtag = arq + \"-grafo-hashtags.csv\"\n",
    "\n",
    "outrow = []\n",
    "with open(arq_csv, \"r\",encoding='utf-8') as fileIn:  # input file location\n",
    "    with open(arq_grafo, \"w\",encoding='utf-8') as fileOut:  # output file location\n",
    "        writer = csv.writer(fileOut)\n",
    "        reader = csv.reader(fileIn, delimiter=';')\n",
    "        writer.writerow(['id','created_at','media_type','retweet_count','favorite_count','lang','coleta','source','target','text'])\n",
    "        for row in reader:\n",
    "            idd = row[0]\n",
    "            created_at = row[1]\n",
    "            media_type = row[2]\n",
    "            retweet_count = row[3]\n",
    "            favorite_count = row[4]\n",
    "            lang = row[5]\n",
    "            coleta = row[6]\n",
    "            screen_name = row[7]\n",
    "            target = ''\n",
    "            text = row[8]\n",
    "\n",
    "            for cell in row:\n",
    "                target = re.findall(r\"@([^\\s]+)\", cell)\n",
    "                target = re.sub(r\"\\[|\\'|\\:|\\]\", '', str(target))\n",
    "                outrow \n",
    "            writer.writerow([idd, created_at, media_type, retweet_count, favorite_count, lang, coleta, screen_name, target, text])\n",
    "\n",
    "df = pd.read_csv(arq_grafo)\n",
    "# print(df.head(3))\n",
    "df['target'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['target'], inplace=True)\n",
    "df.to_csv(arq_grafo, index=False)\n",
    "\n",
    "df = pd.read_csv(arq_grafo)\n",
    "rt = df['text'].str.startswith('RT @')\n",
    "\n",
    "df[rt].to_csv(arq_rt, index=False)\n",
    "df2 = pd.read_csv(arq_rt)\n",
    "df2['target'].replace(r\",[\\s\\S]*$\", \"\", regex=True, inplace= True)\n",
    "df2.to_csv(arq_rt, index=False)\n",
    "\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = df['target'].str.split(',').map(len)\n",
    "\n",
    "res = pd.DataFrame({\n",
    "                    'source': np.repeat(df['source'], lens),\n",
    "                    'target': chainer(df['target']),\n",
    "                    'text': np.repeat(df['text'], lens),\n",
    "                    'id': np.repeat(df['id'], lens),\n",
    "                    'created_at': np.repeat(df['created_at'], lens),\n",
    "                    'media_type': np.repeat(df['media_type'], lens),\n",
    "                    'retweet_count': np.repeat(df['retweet_count'], lens),\n",
    "                    'favorite_count': np.repeat(df['favorite_count'], lens),\n",
    "                    'lang': np.repeat(df['lang'], lens),\n",
    "                    'coleta': np.repeat(df['coleta'], lens)\n",
    "                    })\n",
    "\n",
    "res['target'].replace('', np.nan, inplace=True)\n",
    "res.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "mt = ~res['text'].str.startswith('RT @')\n",
    "res[mt].to_csv(arq_mt, index=False)\n",
    "\n",
    "outrow = []\n",
    "with open(arq_csv, \"r\",encoding='utf-8') as fileIn:  # input file location\n",
    "    with open(arq_grafo, \"w\", encoding='utf-8') as fileOut:  # output file location\n",
    "        writer = csv.writer(fileOut)\n",
    "        reader = csv.reader(fileIn, delimiter=',')\n",
    "        writer.writerow(['hashtags'])\n",
    "        for row in reader:\n",
    "            # screen_name = row[0]      \n",
    "            hashtags = ''\n",
    "            for cell in row:\n",
    "                hashtags = re.findall(r\"#([^\\s]+)\", cell)\n",
    "                hashtags = re.sub(r\"\\[|\\'|\\:|\\]\", '', str(hashtags))\n",
    "                # hashtags = re.sub('['+string.punctuation+']', '', hashtags)\n",
    "                hashtags = re.sub(r\"[^\\P{P},]+\", \"\", hashtags)\n",
    "                hashtags = re.sub(r\"^\\s|\\s|\\s\\s\",\"\",hashtags)\n",
    "                outrow \n",
    "            writer.writerow([hashtags])\n",
    "\n",
    "dfRW = pd.read_csv(arq_grafo)\n",
    "dfRW['hashtags'].replace('', np.nan, inplace=True)\n",
    "dfRW.dropna(subset=['hashtags'], inplace=True)\n",
    "dfRW.to_csv(arq_grafo, index=False)\n",
    "\n",
    "with open(arq_grafo, encoding=\"utf-8\") as f:\n",
    "    vTweets = [row[\"hashtags\"] for row in DictReader(f)]\n",
    "\n",
    "col1=[]\n",
    "col2=[]\n",
    "\n",
    "for tweet in vTweets:\n",
    "    # print(tweet)\n",
    "    vPalavras = tweet.split(',')\n",
    "    nPalavras = len(vPalavras)\n",
    "\n",
    "    if nPalavras > 2:\n",
    "        nLinhas = 0\n",
    "        vNumeros = []\n",
    "        for i in range(nPalavras):\n",
    "            b = nPalavras-(i+1)\n",
    "            if b>0:\n",
    "                vNumeros.append(b)\n",
    "            nLinhas = nLinhas + b\n",
    "\n",
    "        nNumeros= len(vNumeros)\n",
    "        invNumeros = vNumeros[::-1]\n",
    "        \n",
    "        c1 = []\n",
    "        for i in range(nNumeros):\n",
    "            for j in range(vNumeros[i]):\n",
    "                c1.append(vPalavras[i])  \n",
    "        col1.extend(c1)\n",
    "\n",
    "\n",
    "        ordemC2 = []\n",
    "        for i in range(nNumeros):\n",
    "            for j in invNumeros:\n",
    "                ordemC2.append(j)\n",
    "            invNumeros.pop(0)\n",
    "\n",
    "        Mposicao = []\n",
    "        posicaoC2 = []\n",
    "        for i in range(int(nLinhas/nPalavras)):\n",
    "            for j in range(nPalavras):\n",
    "                posicaoC2.append(vPalavras[j])\n",
    "                Mposicao.append(j)\n",
    "\n",
    "        c2 =[]\n",
    "        c2[:] = [posicaoC2[i] for i in ordemC2]\n",
    "        col2.extend(c2)\n",
    "\n",
    "# usr = pd.DataFrame({'source': np.repeat(df['source'], lens),\n",
    "# usr = dfRW['usuario'].values[0]\n",
    "# n = len(col1)\n",
    "# usrs = [usr]*n\n",
    "\n",
    "matriz = np.c_[col1,col2]\n",
    "df = pd.DataFrame(columns=[\"source\",\"target\"], data=matriz)\n",
    "df['source'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['source'], inplace=True)\n",
    "df['target'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['target'], inplace=True)\n",
    "\n",
    "df.to_csv(arq_hashtag, index=False)\n",
    "os.remove(arq_grafo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDeputados = pd.read_csv(\"dados-twitter/tweetsDeputados-F.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "tweetsDeputados_T100 = tweetsDeputados.nlargest(100,\"retweet_count\")\n",
    "tweetsDeputados_T100S = tweetsDeputados_T100['text']\n",
    "tweetsDeputados_T100S.head(4)\n",
    "# tweetsDeputados_T100.shape[0]\n",
    "tweetsDeputados_T100S.to_csv(\"dados-twitter/tweetsDeputados-T100S.csv\", sep=\";\", encoding=\"utf-8\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
